{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9311157,"sourceType":"datasetVersion","datasetId":5639065}],"dockerImageVersionId":30762,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nfrom sklearn.datasets import make_classification\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import NearestNeighbors\nfrom imblearn.over_sampling import SMOTE, BorderlineSMOTE, ADASYN\nfrom imblearn.under_sampling import EditedNearestNeighbours\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras import layers, models\nimport tensorflow as tf\nimport pickle\nfrom tensorflow.keras.layers import Activation\nfrom tensorflow.keras.layers import Flatten\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.layers import Reshape\nfrom tensorflow.keras.layers import Input,Dropout\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Dot\nfrom tensorflow.keras.layers import Lambda\nfrom tensorflow.keras import backend as K\nimport keras\nimport random\nimport numpy as np\nimport os\nfrom PIL import Image\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.losses import SparseCategoricalCrossentropy\nfrom tensorflow.keras.metrics import SparseCategoricalAccuracy\n\nimport numpy as np\nfrom sklearn.datasets import make_classification\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import NearestNeighbors\nfrom imblearn.over_sampling import SMOTE, BorderlineSMOTE, ADASYN\nfrom imblearn.under_sampling import EditedNearestNeighbours\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras import layers, models\nimport tensorflow as tf\nimport pickle\nfrom tensorflow.keras.layers import Activation\nfrom tensorflow.keras.layers import Flatten\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.layers import Reshape\nfrom tensorflow.keras.layers import Input,Dropout\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Dot\nfrom tensorflow.keras.layers import Lambda\nfrom tensorflow.keras import backend as K\nimport keras\nimport random\nimport numpy as np\nimport os\nfrom PIL import Image\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.layers import GlobalAveragePooling2D, Dense, BatchNormalization, Dropout\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator","metadata":{"execution":{"iopub.status.busy":"2024-09-10T07:26:51.549784Z","iopub.execute_input":"2024-09-10T07:26:51.550682Z","iopub.status.idle":"2024-09-10T07:27:05.367849Z","shell.execute_reply.started":"2024-09-10T07:26:51.550604Z","shell.execute_reply":"2024-09-10T07:27:05.366879Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import os\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom imblearn.over_sampling import SMOTE\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.preprocessing.image import img_to_array, load_img\nfrom sklearn.preprocessing import LabelEncoder\n\n\n# Define directories\ntrain_dir = '/kaggle/input/plantdoc/PlantDoc-Dataset/train' \ntest_dir = '/kaggle/input/plantdoc/PlantDoc-Dataset/test'    \n\n# Parameters\nimg_height, img_width = 64, 64  \nbatch_size = 32\nnum_classes = 27  \n\n\ndef load_images_from_directory(directory):\n    images = []\n    labels = []\n    classes = os.listdir(directory)\n    for label in classes:\n        class_dir = os.path.join(directory, label)\n        if os.path.isdir(class_dir):\n            for img_name in os.listdir(class_dir):\n                img_path = os.path.join(class_dir, img_name)\n                img = load_img(img_path, target_size=(img_height, img_width))\n                img_array = img_to_array(img)\n                images.append(img_array)\n                labels.append(label)\n    return np.array(images), np.array(labels)\n\nx_train, y_train = load_images_from_directory(train_dir)\nx_test, y_test = load_images_from_directory(test_dir)\n\nlabel_encoder = LabelEncoder()\n\ny_train_encoded = label_encoder.fit_transform(y_train)\ny_test_encoded = label_encoder.transform(y_test)\n\ny_train_encoded = to_categorical(y_train_encoded, num_classes=num_classes)\ny_test_encoded = to_categorical(y_test_encoded, num_classes=num_classes)\n\nx_train, x_val, y_train, y_val = train_test_split(x_train, y_train_encoded, test_size=0.2, stratify=y_train)\n\ndatagen = ImageDataGenerator(\n    rotation_range=20,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    fill_mode='nearest'\n)\n\nx_train_aug = []\ny_train_aug = []\nfor i in range(len(x_train)):\n    aug_iter = datagen.flow(x_train[i:i+1], y_train[i:i+1], batch_size=1)\n    x_aug, y_aug = next(aug_iter)\n    x_train_aug.append(x_aug[0])\n    y_train_aug.append(y_aug[0])\n\nx_train_aug = np.array(x_train_aug)\ny_train_aug = np.array(y_train_aug)\n\nx_train_flat = x_train_aug.reshape((x_train_aug.shape[0], -1))  \nsmote = SMOTE(random_state=42)\nx_train_resampled, y_train_resampled = smote.fit_resample(x_train_flat, y_train_aug)\n\nx_train_resampled = x_train_resampled.reshape(-1, img_height, img_width, 3)\n\ntrain_generator = datagen.flow(x_train_resampled, y_train_resampled, batch_size=batch_size)","metadata":{"execution":{"iopub.status.busy":"2024-09-10T07:27:05.370157Z","iopub.execute_input":"2024-09-10T07:27:05.370895Z","iopub.status.idle":"2024-09-10T07:28:02.179788Z","shell.execute_reply.started":"2024-09-10T07:27:05.370846Z","shell.execute_reply":"2024-09-10T07:28:02.178739Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.applications import ResNet50, InceptionV3, MobileNetV2, EfficientNetB0, VGG16\nfrom tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Flatten\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.models import Sequential\n\nnum_classes = 27\n\ninput_shape = (64, 64, 3)\n\ndef create_resnet50_model(input_shape, num_classes):\n    base_model = ResNet50(weights='imagenet', include_top=False, input_shape=input_shape)\n    \n    model = Sequential()\n    model.add(base_model)  \n    model.add(GlobalAveragePooling2D())  \n    model.add(Dense(1024, activation='relu'))  \n    model.add(Dense(num_classes, activation='softmax'))  \n\n    return model\n\nresnet50_model = create_resnet50_model(input_shape, num_classes)\nresnet50_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n\ndef create_mobilenetv2_model(input_shape, num_classes):\n    base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=input_shape)\n    \n    model = Sequential()\n    model.add(base_model)  \n    model.add(GlobalAveragePooling2D())  \n    model.add(Dense(1024, activation='relu')) \n    model.add(Dense(num_classes, activation='softmax'))\n\n    return model\n\nmobilenetv2_model = create_mobilenetv2_model(input_shape, num_classes)\nmobilenetv2_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n\ndef create_efficientnetb0_model(input_shape, num_classes):\n    base_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=input_shape)\n    \n    model = Sequential()\n    model.add(base_model)  \n    model.add(GlobalAveragePooling2D())  \n    model.add(Dense(1024, activation='relu'))  \n    model.add(Dense(num_classes, activation='softmax'))  \n\n    return model\n\nefficientnetb0_model = create_efficientnetb0_model(input_shape, num_classes)\nefficientnetb0_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n\ndef create_vgg16_model(input_shape, num_classes):\n    base_model = VGG16(weights='imagenet', include_top=False, input_shape=input_shape)\n    \n    model = Sequential()\n    model.add(base_model)  \n    model.add(GlobalAveragePooling2D())  \n    model.add(Dense(1024, activation='relu'))  \n    model.add(Dense(num_classes, activation='softmax'))  \n\n    return model\n\nvgg16_model = create_vgg16_model(input_shape, num_classes)\nvgg16_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2024-09-10T08:33:35.202878Z","iopub.execute_input":"2024-09-10T08:33:35.203519Z","iopub.status.idle":"2024-09-10T08:33:38.357093Z","shell.execute_reply.started":"2024-09-10T08:33:35.203465Z","shell.execute_reply":"2024-09-10T08:33:38.356177Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_37/559834048.py:29: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n  base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=input_shape)\n","output_type":"stream"}]},{"cell_type":"code","source":"history1 = resnet50_model.fit(train_generator, epochs=100, validation_data=(x_val, y_val))\nloss, accuracy = resnet_model.evaluate(x_test,y_test_encoded)\nprint(f\"Test accuracy: {accuracy}\")","metadata":{"execution":{"iopub.status.busy":"2024-09-10T08:12:15.153621Z","iopub.execute_input":"2024-09-10T08:12:15.154339Z","iopub.status.idle":"2024-09-10T08:24:11.328532Z","shell.execute_reply.started":"2024-09-10T08:12:15.154298Z","shell.execute_reply":"2024-09-10T08:24:11.327576Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Epoch 1/100\n\u001b[1m  1/122\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:35:43\u001b[0m 47s/step - accuracy: 0.0000e+00 - loss: 3.9779","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1725955982.582500     113 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'loop_add_subtract_fusion_28', 20 bytes spill stores, 20 bytes spill loads\n\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 208ms/step - accuracy: 0.0932 - loss: 3.5147 - val_accuracy: 0.0754 - val_loss: 18.0809\nEpoch 2/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 52ms/step - accuracy: 0.2530 - loss: 2.6524 - val_accuracy: 0.0690 - val_loss: 63.9065\nEpoch 3/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 52ms/step - accuracy: 0.2952 - loss: 2.4111 - val_accuracy: 0.0927 - val_loss: 6.1883\nEpoch 4/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 51ms/step - accuracy: 0.3367 - loss: 2.2652 - val_accuracy: 0.1121 - val_loss: 4.6924\nEpoch 5/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 53ms/step - accuracy: 0.3777 - loss: 2.0977 - val_accuracy: 0.1401 - val_loss: 4.8668\nEpoch 6/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 52ms/step - accuracy: 0.4224 - loss: 1.9280 - val_accuracy: 0.1250 - val_loss: 4.9690\nEpoch 7/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 52ms/step - accuracy: 0.4711 - loss: 1.7464 - val_accuracy: 0.1595 - val_loss: 4.2542\nEpoch 8/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 50ms/step - accuracy: 0.4899 - loss: 1.6987 - val_accuracy: 0.1638 - val_loss: 4.9859\nEpoch 9/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 49ms/step - accuracy: 0.5174 - loss: 1.5440 - val_accuracy: 0.1422 - val_loss: 5.0702\nEpoch 10/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 51ms/step - accuracy: 0.5437 - loss: 1.4664 - val_accuracy: 0.1293 - val_loss: 7.5440\nEpoch 11/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 49ms/step - accuracy: 0.5874 - loss: 1.3616 - val_accuracy: 0.0819 - val_loss: 11.7515\nEpoch 12/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 50ms/step - accuracy: 0.6290 - loss: 1.2204 - val_accuracy: 0.1444 - val_loss: 6.0607\nEpoch 13/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 51ms/step - accuracy: 0.6348 - loss: 1.1831 - val_accuracy: 0.1552 - val_loss: 4.5377\nEpoch 14/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 53ms/step - accuracy: 0.6717 - loss: 1.0649 - val_accuracy: 0.2047 - val_loss: 6.0847\nEpoch 15/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 51ms/step - accuracy: 0.6742 - loss: 1.0512 - val_accuracy: 0.2306 - val_loss: 4.0842\nEpoch 16/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 50ms/step - accuracy: 0.7122 - loss: 0.9520 - val_accuracy: 0.1207 - val_loss: 7.1632\nEpoch 17/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 50ms/step - accuracy: 0.7184 - loss: 0.8896 - val_accuracy: 0.1918 - val_loss: 5.0390\nEpoch 18/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 50ms/step - accuracy: 0.7398 - loss: 0.7977 - val_accuracy: 0.2112 - val_loss: 4.6988\nEpoch 19/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 52ms/step - accuracy: 0.7608 - loss: 0.7946 - val_accuracy: 0.1659 - val_loss: 8.1831\nEpoch 20/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 50ms/step - accuracy: 0.7663 - loss: 0.7376 - val_accuracy: 0.2694 - val_loss: 4.7605\nEpoch 21/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 51ms/step - accuracy: 0.8032 - loss: 0.6349 - val_accuracy: 0.1703 - val_loss: 6.8629\nEpoch 22/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 52ms/step - accuracy: 0.8025 - loss: 0.6127 - val_accuracy: 0.1940 - val_loss: 5.7961\nEpoch 23/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 50ms/step - accuracy: 0.7941 - loss: 0.6426 - val_accuracy: 0.1940 - val_loss: 5.9012\nEpoch 24/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 54ms/step - accuracy: 0.7994 - loss: 0.6220 - val_accuracy: 0.2478 - val_loss: 4.0648\nEpoch 25/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 51ms/step - accuracy: 0.8227 - loss: 0.5622 - val_accuracy: 0.2198 - val_loss: 4.8250\nEpoch 26/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 51ms/step - accuracy: 0.8274 - loss: 0.5355 - val_accuracy: 0.2435 - val_loss: 5.0013\nEpoch 27/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 52ms/step - accuracy: 0.8477 - loss: 0.4895 - val_accuracy: 0.1940 - val_loss: 4.9353\nEpoch 28/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 51ms/step - accuracy: 0.8453 - loss: 0.4820 - val_accuracy: 0.2069 - val_loss: 6.4761\nEpoch 29/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 53ms/step - accuracy: 0.8691 - loss: 0.4168 - val_accuracy: 0.1940 - val_loss: 5.9479\nEpoch 30/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 50ms/step - accuracy: 0.8629 - loss: 0.4653 - val_accuracy: 0.2392 - val_loss: 6.3869\nEpoch 31/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 50ms/step - accuracy: 0.8498 - loss: 0.5024 - val_accuracy: 0.1659 - val_loss: 6.5373\nEpoch 32/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 50ms/step - accuracy: 0.8745 - loss: 0.3925 - val_accuracy: 0.1940 - val_loss: 5.2261\nEpoch 33/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 50ms/step - accuracy: 0.8695 - loss: 0.3988 - val_accuracy: 0.2134 - val_loss: 5.1964\nEpoch 34/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 53ms/step - accuracy: 0.8659 - loss: 0.4125 - val_accuracy: 0.2026 - val_loss: 7.1208\nEpoch 35/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 50ms/step - accuracy: 0.8766 - loss: 0.3890 - val_accuracy: 0.2241 - val_loss: 5.5590\nEpoch 36/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 50ms/step - accuracy: 0.8919 - loss: 0.3231 - val_accuracy: 0.1315 - val_loss: 7.8625\nEpoch 37/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 49ms/step - accuracy: 0.8814 - loss: 0.3680 - val_accuracy: 0.2414 - val_loss: 5.7460\nEpoch 38/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 50ms/step - accuracy: 0.8889 - loss: 0.3295 - val_accuracy: 0.2069 - val_loss: 5.7542\nEpoch 39/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 52ms/step - accuracy: 0.8987 - loss: 0.3249 - val_accuracy: 0.2112 - val_loss: 7.2204\nEpoch 40/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 49ms/step - accuracy: 0.9119 - loss: 0.2728 - val_accuracy: 0.2047 - val_loss: 6.6950\nEpoch 41/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 51ms/step - accuracy: 0.9005 - loss: 0.3280 - val_accuracy: 0.1724 - val_loss: 8.5278\nEpoch 42/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 51ms/step - accuracy: 0.9096 - loss: 0.3097 - val_accuracy: 0.2414 - val_loss: 5.9763\nEpoch 43/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 51ms/step - accuracy: 0.9168 - loss: 0.2760 - val_accuracy: 0.1552 - val_loss: 7.9361\nEpoch 44/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 52ms/step - accuracy: 0.9028 - loss: 0.2969 - val_accuracy: 0.1789 - val_loss: 7.6455\nEpoch 45/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 49ms/step - accuracy: 0.9103 - loss: 0.2683 - val_accuracy: 0.1961 - val_loss: 6.8926\nEpoch 46/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 49ms/step - accuracy: 0.9038 - loss: 0.3178 - val_accuracy: 0.1940 - val_loss: 7.8760\nEpoch 47/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 51ms/step - accuracy: 0.9161 - loss: 0.2833 - val_accuracy: 0.2457 - val_loss: 5.3644\nEpoch 48/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 49ms/step - accuracy: 0.9242 - loss: 0.2558 - val_accuracy: 0.1961 - val_loss: 6.9374\nEpoch 49/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 52ms/step - accuracy: 0.9193 - loss: 0.2670 - val_accuracy: 0.2004 - val_loss: 7.1760\nEpoch 50/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 49ms/step - accuracy: 0.9119 - loss: 0.2769 - val_accuracy: 0.2414 - val_loss: 5.3994\nEpoch 51/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 49ms/step - accuracy: 0.9220 - loss: 0.2594 - val_accuracy: 0.2414 - val_loss: 6.4914\nEpoch 52/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 49ms/step - accuracy: 0.9374 - loss: 0.2133 - val_accuracy: 0.2392 - val_loss: 5.6518\nEpoch 53/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 50ms/step - accuracy: 0.9319 - loss: 0.2260 - val_accuracy: 0.1940 - val_loss: 8.0665\nEpoch 54/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 52ms/step - accuracy: 0.9271 - loss: 0.2320 - val_accuracy: 0.2026 - val_loss: 7.8659\nEpoch 55/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 50ms/step - accuracy: 0.9168 - loss: 0.2670 - val_accuracy: 0.1983 - val_loss: 7.1651\nEpoch 56/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 51ms/step - accuracy: 0.9290 - loss: 0.2229 - val_accuracy: 0.2198 - val_loss: 9.2106\nEpoch 57/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 51ms/step - accuracy: 0.9281 - loss: 0.2189 - val_accuracy: 0.2155 - val_loss: 7.5886\nEpoch 58/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 51ms/step - accuracy: 0.9341 - loss: 0.2124 - val_accuracy: 0.2371 - val_loss: 7.2242\nEpoch 59/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 54ms/step - accuracy: 0.9331 - loss: 0.2123 - val_accuracy: 0.2737 - val_loss: 5.3025\nEpoch 60/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 49ms/step - accuracy: 0.9343 - loss: 0.1964 - val_accuracy: 0.2026 - val_loss: 8.0303\nEpoch 61/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 51ms/step - accuracy: 0.9384 - loss: 0.1966 - val_accuracy: 0.1961 - val_loss: 7.0968\nEpoch 62/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 52ms/step - accuracy: 0.9217 - loss: 0.2614 - val_accuracy: 0.2004 - val_loss: 9.2736\nEpoch 63/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 50ms/step - accuracy: 0.9364 - loss: 0.2074 - val_accuracy: 0.2414 - val_loss: 5.9002\nEpoch 64/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 53ms/step - accuracy: 0.9353 - loss: 0.2158 - val_accuracy: 0.2349 - val_loss: 7.7073\nEpoch 65/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 50ms/step - accuracy: 0.9443 - loss: 0.1804 - val_accuracy: 0.1530 - val_loss: 10.2934\nEpoch 66/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 49ms/step - accuracy: 0.9335 - loss: 0.2069 - val_accuracy: 0.1810 - val_loss: 6.7421\nEpoch 67/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 51ms/step - accuracy: 0.9299 - loss: 0.2340 - val_accuracy: 0.2435 - val_loss: 6.5662\nEpoch 68/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 51ms/step - accuracy: 0.9351 - loss: 0.2051 - val_accuracy: 0.1940 - val_loss: 8.2512\nEpoch 69/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 51ms/step - accuracy: 0.9387 - loss: 0.1992 - val_accuracy: 0.1659 - val_loss: 8.6119\nEpoch 70/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 50ms/step - accuracy: 0.9353 - loss: 0.2272 - val_accuracy: 0.2047 - val_loss: 7.7373\nEpoch 71/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 49ms/step - accuracy: 0.9503 - loss: 0.1661 - val_accuracy: 0.2069 - val_loss: 6.8045\nEpoch 72/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 50ms/step - accuracy: 0.9343 - loss: 0.2114 - val_accuracy: 0.1810 - val_loss: 9.2441\nEpoch 73/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 51ms/step - accuracy: 0.9502 - loss: 0.1483 - val_accuracy: 0.2047 - val_loss: 9.0101\nEpoch 74/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 50ms/step - accuracy: 0.9279 - loss: 0.2376 - val_accuracy: 0.2306 - val_loss: 7.0258\nEpoch 75/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 49ms/step - accuracy: 0.9428 - loss: 0.1885 - val_accuracy: 0.1099 - val_loss: 11.1445\nEpoch 76/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 50ms/step - accuracy: 0.9433 - loss: 0.1737 - val_accuracy: 0.1703 - val_loss: 9.7575\nEpoch 77/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 49ms/step - accuracy: 0.9497 - loss: 0.1519 - val_accuracy: 0.2241 - val_loss: 6.8611\nEpoch 78/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 51ms/step - accuracy: 0.9413 - loss: 0.1826 - val_accuracy: 0.2543 - val_loss: 6.4930\nEpoch 79/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 50ms/step - accuracy: 0.9401 - loss: 0.1789 - val_accuracy: 0.2608 - val_loss: 7.0045\nEpoch 80/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 50ms/step - accuracy: 0.9517 - loss: 0.1628 - val_accuracy: 0.2091 - val_loss: 8.7693\nEpoch 81/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 49ms/step - accuracy: 0.9483 - loss: 0.1557 - val_accuracy: 0.2177 - val_loss: 7.5669\nEpoch 82/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 50ms/step - accuracy: 0.9516 - loss: 0.1491 - val_accuracy: 0.2629 - val_loss: 6.8321\nEpoch 83/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 51ms/step - accuracy: 0.9588 - loss: 0.1492 - val_accuracy: 0.1293 - val_loss: 10.9758\nEpoch 84/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 51ms/step - accuracy: 0.9568 - loss: 0.1418 - val_accuracy: 0.2241 - val_loss: 6.7915\nEpoch 85/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 49ms/step - accuracy: 0.9455 - loss: 0.1651 - val_accuracy: 0.2069 - val_loss: 7.8902\nEpoch 86/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 49ms/step - accuracy: 0.9406 - loss: 0.1747 - val_accuracy: 0.2069 - val_loss: 9.5172\nEpoch 87/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 49ms/step - accuracy: 0.9457 - loss: 0.1851 - val_accuracy: 0.2177 - val_loss: 7.6438\nEpoch 88/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 52ms/step - accuracy: 0.9546 - loss: 0.1409 - val_accuracy: 0.2069 - val_loss: 7.5093\nEpoch 89/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 50ms/step - accuracy: 0.9505 - loss: 0.1596 - val_accuracy: 0.2737 - val_loss: 6.9245\nEpoch 90/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 51ms/step - accuracy: 0.9476 - loss: 0.1705 - val_accuracy: 0.2328 - val_loss: 6.9380\nEpoch 91/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 50ms/step - accuracy: 0.9543 - loss: 0.1495 - val_accuracy: 0.2026 - val_loss: 10.8623\nEpoch 92/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 50ms/step - accuracy: 0.9621 - loss: 0.1231 - val_accuracy: 0.2392 - val_loss: 6.9507\nEpoch 93/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 51ms/step - accuracy: 0.9618 - loss: 0.1232 - val_accuracy: 0.1961 - val_loss: 9.8572\nEpoch 94/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 49ms/step - accuracy: 0.9570 - loss: 0.1391 - val_accuracy: 0.2091 - val_loss: 6.9155\nEpoch 95/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 51ms/step - accuracy: 0.9522 - loss: 0.1570 - val_accuracy: 0.2112 - val_loss: 9.7078\nEpoch 96/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 49ms/step - accuracy: 0.9540 - loss: 0.1671 - val_accuracy: 0.2198 - val_loss: 9.5269\nEpoch 97/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 49ms/step - accuracy: 0.9655 - loss: 0.1239 - val_accuracy: 0.2177 - val_loss: 9.9332\nEpoch 98/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 53ms/step - accuracy: 0.9613 - loss: 0.1210 - val_accuracy: 0.2586 - val_loss: 7.5852\nEpoch 99/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 49ms/step - accuracy: 0.9552 - loss: 0.1514 - val_accuracy: 0.2263 - val_loss: 8.0751\nEpoch 100/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 50ms/step - accuracy: 0.9551 - loss: 0.1551 - val_accuracy: 0.1853 - val_loss: 10.3380\n\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.2172 - loss: 8.6732\nTest accuracy: 0.18644067645072937\n","output_type":"stream"}]},{"cell_type":"code","source":"history2 = mobilenetv2_model.fit(train_generator, epochs=100, validation_data=(x_val, y_val))\nloss, accuracy = mobilenetv2_model.evaluate(x_test,y_test_encoded)\nprint(f\"Test accuracy: {accuracy}\")","metadata":{"execution":{"iopub.status.busy":"2024-09-10T08:35:45.765598Z","iopub.execute_input":"2024-09-10T08:35:45.765994Z","iopub.status.idle":"2024-09-10T08:45:56.459994Z","shell.execute_reply.started":"2024-09-10T08:35:45.765956Z","shell.execute_reply":"2024-09-10T08:45:56.458986Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"Epoch 1/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 86ms/step - accuracy: 0.1776 - loss: 2.9378 - val_accuracy: 0.0647 - val_loss: 5.1614\nEpoch 2/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 51ms/step - accuracy: 0.2551 - loss: 2.6160 - val_accuracy: 0.0625 - val_loss: 5.0643\nEpoch 3/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 52ms/step - accuracy: 0.3414 - loss: 2.2823 - val_accuracy: 0.1250 - val_loss: 3.7224\nEpoch 4/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 49ms/step - accuracy: 0.3783 - loss: 2.1096 - val_accuracy: 0.0776 - val_loss: 6.0263\nEpoch 5/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.4041 - loss: 2.0400 - val_accuracy: 0.0560 - val_loss: 6.0312\nEpoch 6/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 48ms/step - accuracy: 0.4075 - loss: 1.9320 - val_accuracy: 0.1056 - val_loss: 5.0931\nEpoch 7/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 50ms/step - accuracy: 0.4631 - loss: 1.7786 - val_accuracy: 0.0388 - val_loss: 5.7036\nEpoch 8/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 51ms/step - accuracy: 0.4716 - loss: 1.7308 - val_accuracy: 0.1013 - val_loss: 5.9083\nEpoch 9/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 46ms/step - accuracy: 0.5312 - loss: 1.5547 - val_accuracy: 0.1336 - val_loss: 3.7693\nEpoch 10/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 45ms/step - accuracy: 0.5348 - loss: 1.5279 - val_accuracy: 0.1078 - val_loss: 5.2622\nEpoch 11/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 45ms/step - accuracy: 0.5544 - loss: 1.5033 - val_accuracy: 0.1659 - val_loss: 4.6043\nEpoch 12/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 45ms/step - accuracy: 0.5949 - loss: 1.3139 - val_accuracy: 0.1638 - val_loss: 5.7185\nEpoch 13/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 45ms/step - accuracy: 0.5846 - loss: 1.3339 - val_accuracy: 0.1379 - val_loss: 5.1734\nEpoch 14/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 45ms/step - accuracy: 0.6032 - loss: 1.2960 - val_accuracy: 0.1142 - val_loss: 8.4057\nEpoch 15/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 46ms/step - accuracy: 0.6323 - loss: 1.1947 - val_accuracy: 0.1487 - val_loss: 5.7534\nEpoch 16/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 45ms/step - accuracy: 0.6358 - loss: 1.2042 - val_accuracy: 0.1315 - val_loss: 7.5681\nEpoch 17/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 46ms/step - accuracy: 0.6424 - loss: 1.1854 - val_accuracy: 0.1358 - val_loss: 5.6727\nEpoch 18/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 48ms/step - accuracy: 0.6786 - loss: 1.0626 - val_accuracy: 0.1078 - val_loss: 6.1649\nEpoch 19/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 45ms/step - accuracy: 0.6827 - loss: 0.9798 - val_accuracy: 0.0841 - val_loss: 7.0186\nEpoch 20/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 46ms/step - accuracy: 0.6931 - loss: 1.0042 - val_accuracy: 0.1422 - val_loss: 5.2495\nEpoch 21/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 46ms/step - accuracy: 0.7155 - loss: 0.9298 - val_accuracy: 0.0690 - val_loss: 8.2291\nEpoch 22/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 46ms/step - accuracy: 0.7133 - loss: 0.9392 - val_accuracy: 0.1142 - val_loss: 7.9093\nEpoch 23/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 48ms/step - accuracy: 0.7236 - loss: 0.8948 - val_accuracy: 0.1315 - val_loss: 5.8821\nEpoch 24/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 46ms/step - accuracy: 0.7279 - loss: 0.8780 - val_accuracy: 0.1228 - val_loss: 6.9236\nEpoch 25/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.7337 - loss: 0.8884 - val_accuracy: 0.1616 - val_loss: 5.5923\nEpoch 26/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 46ms/step - accuracy: 0.7579 - loss: 0.8093 - val_accuracy: 0.2220 - val_loss: 5.2439\nEpoch 27/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 48ms/step - accuracy: 0.7527 - loss: 0.8039 - val_accuracy: 0.1616 - val_loss: 5.1289\nEpoch 28/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.7446 - loss: 0.8259 - val_accuracy: 0.1616 - val_loss: 6.7669\nEpoch 29/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.7554 - loss: 0.7528 - val_accuracy: 0.1272 - val_loss: 6.0038\nEpoch 30/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 46ms/step - accuracy: 0.7636 - loss: 0.7742 - val_accuracy: 0.1444 - val_loss: 7.5801\nEpoch 31/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.7682 - loss: 0.7191 - val_accuracy: 0.0884 - val_loss: 8.8809\nEpoch 32/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.7766 - loss: 0.7047 - val_accuracy: 0.1379 - val_loss: 6.9066\nEpoch 33/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.7750 - loss: 0.6962 - val_accuracy: 0.1164 - val_loss: 7.0352\nEpoch 34/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 50ms/step - accuracy: 0.7690 - loss: 0.7359 - val_accuracy: 0.1595 - val_loss: 6.5164\nEpoch 35/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.7790 - loss: 0.6809 - val_accuracy: 0.1422 - val_loss: 9.3748\nEpoch 36/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 46ms/step - accuracy: 0.7906 - loss: 0.6642 - val_accuracy: 0.1853 - val_loss: 6.4562\nEpoch 37/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.7940 - loss: 0.6309 - val_accuracy: 0.1940 - val_loss: 6.2536\nEpoch 38/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 48ms/step - accuracy: 0.8140 - loss: 0.5776 - val_accuracy: 0.2004 - val_loss: 7.4731\nEpoch 39/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.8207 - loss: 0.5839 - val_accuracy: 0.1703 - val_loss: 7.1609\nEpoch 40/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 46ms/step - accuracy: 0.7943 - loss: 0.6223 - val_accuracy: 0.2004 - val_loss: 6.5086\nEpoch 41/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 46ms/step - accuracy: 0.8131 - loss: 0.5771 - val_accuracy: 0.1573 - val_loss: 9.4823\nEpoch 42/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 46ms/step - accuracy: 0.8146 - loss: 0.5479 - val_accuracy: 0.1703 - val_loss: 7.1552\nEpoch 43/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 45ms/step - accuracy: 0.8354 - loss: 0.5424 - val_accuracy: 0.1659 - val_loss: 8.2227\nEpoch 44/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 45ms/step - accuracy: 0.8431 - loss: 0.4874 - val_accuracy: 0.1509 - val_loss: 6.2661\nEpoch 45/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 46ms/step - accuracy: 0.8145 - loss: 0.5776 - val_accuracy: 0.1013 - val_loss: 8.7899\nEpoch 46/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 44ms/step - accuracy: 0.7897 - loss: 0.6633 - val_accuracy: 0.1487 - val_loss: 7.1084\nEpoch 47/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 44ms/step - accuracy: 0.8438 - loss: 0.5013 - val_accuracy: 0.1789 - val_loss: 6.3184\nEpoch 48/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 44ms/step - accuracy: 0.8424 - loss: 0.4851 - val_accuracy: 0.2457 - val_loss: 5.6572\nEpoch 49/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 44ms/step - accuracy: 0.8610 - loss: 0.4660 - val_accuracy: 0.1724 - val_loss: 7.5782\nEpoch 50/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 46ms/step - accuracy: 0.8360 - loss: 0.4896 - val_accuracy: 0.1444 - val_loss: 8.8285\nEpoch 51/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 44ms/step - accuracy: 0.8200 - loss: 0.5766 - val_accuracy: 0.1961 - val_loss: 6.6747\nEpoch 52/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 45ms/step - accuracy: 0.8347 - loss: 0.5141 - val_accuracy: 0.1552 - val_loss: 7.7351\nEpoch 53/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 44ms/step - accuracy: 0.8492 - loss: 0.4776 - val_accuracy: 0.1616 - val_loss: 7.5490\nEpoch 54/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 44ms/step - accuracy: 0.8439 - loss: 0.4896 - val_accuracy: 0.1595 - val_loss: 6.3815\nEpoch 55/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 44ms/step - accuracy: 0.8605 - loss: 0.4357 - val_accuracy: 0.1616 - val_loss: 5.9057\nEpoch 56/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 45ms/step - accuracy: 0.8726 - loss: 0.4010 - val_accuracy: 0.1530 - val_loss: 7.1694\nEpoch 57/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 45ms/step - accuracy: 0.8610 - loss: 0.4300 - val_accuracy: 0.1746 - val_loss: 6.3927\nEpoch 58/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 45ms/step - accuracy: 0.8589 - loss: 0.4475 - val_accuracy: 0.1724 - val_loss: 7.0693\nEpoch 59/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 45ms/step - accuracy: 0.8559 - loss: 0.4708 - val_accuracy: 0.1616 - val_loss: 7.6246\nEpoch 60/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.8476 - loss: 0.4681 - val_accuracy: 0.1703 - val_loss: 6.0898\nEpoch 61/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 45ms/step - accuracy: 0.8655 - loss: 0.4209 - val_accuracy: 0.2371 - val_loss: 5.8374\nEpoch 62/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 45ms/step - accuracy: 0.8726 - loss: 0.4137 - val_accuracy: 0.1853 - val_loss: 6.1175\nEpoch 63/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 45ms/step - accuracy: 0.8499 - loss: 0.4835 - val_accuracy: 0.1703 - val_loss: 7.0567\nEpoch 64/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 45ms/step - accuracy: 0.8919 - loss: 0.3724 - val_accuracy: 0.1703 - val_loss: 6.2904\nEpoch 65/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 46ms/step - accuracy: 0.8624 - loss: 0.4120 - val_accuracy: 0.1832 - val_loss: 7.8197\nEpoch 66/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.8890 - loss: 0.3494 - val_accuracy: 0.2155 - val_loss: 6.7163\nEpoch 67/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 45ms/step - accuracy: 0.8872 - loss: 0.3651 - val_accuracy: 0.1746 - val_loss: 7.6041\nEpoch 68/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 45ms/step - accuracy: 0.8816 - loss: 0.3705 - val_accuracy: 0.1724 - val_loss: 7.5608\nEpoch 69/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 44ms/step - accuracy: 0.8664 - loss: 0.4086 - val_accuracy: 0.2155 - val_loss: 6.2609\nEpoch 70/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 46ms/step - accuracy: 0.8709 - loss: 0.4076 - val_accuracy: 0.2134 - val_loss: 6.4535\nEpoch 71/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 48ms/step - accuracy: 0.8920 - loss: 0.3323 - val_accuracy: 0.1810 - val_loss: 6.3738\nEpoch 72/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 46ms/step - accuracy: 0.8652 - loss: 0.4109 - val_accuracy: 0.1573 - val_loss: 7.3350\nEpoch 73/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 46ms/step - accuracy: 0.8252 - loss: 0.5579 - val_accuracy: 0.1552 - val_loss: 7.7748\nEpoch 74/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 45ms/step - accuracy: 0.8655 - loss: 0.4078 - val_accuracy: 0.2091 - val_loss: 6.9341\nEpoch 75/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 46ms/step - accuracy: 0.8888 - loss: 0.3767 - val_accuracy: 0.1142 - val_loss: 7.8573\nEpoch 76/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 45ms/step - accuracy: 0.8293 - loss: 0.5368 - val_accuracy: 0.1466 - val_loss: 9.4729\nEpoch 77/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.9069 - loss: 0.3195 - val_accuracy: 0.1767 - val_loss: 7.0314\nEpoch 78/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 46ms/step - accuracy: 0.9082 - loss: 0.2911 - val_accuracy: 0.1918 - val_loss: 6.3046\nEpoch 79/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.9167 - loss: 0.2689 - val_accuracy: 0.2112 - val_loss: 7.4952\nEpoch 80/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.9268 - loss: 0.2521 - val_accuracy: 0.1509 - val_loss: 8.7750\nEpoch 81/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 46ms/step - accuracy: 0.8730 - loss: 0.4097 - val_accuracy: 0.1918 - val_loss: 7.8833\nEpoch 82/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 46ms/step - accuracy: 0.9008 - loss: 0.3201 - val_accuracy: 0.1595 - val_loss: 6.3556\nEpoch 83/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 45ms/step - accuracy: 0.9148 - loss: 0.2744 - val_accuracy: 0.1616 - val_loss: 6.4803\nEpoch 84/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 45ms/step - accuracy: 0.9146 - loss: 0.2662 - val_accuracy: 0.1789 - val_loss: 7.5726\nEpoch 85/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 46ms/step - accuracy: 0.9139 - loss: 0.2539 - val_accuracy: 0.1638 - val_loss: 8.0440\nEpoch 86/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 45ms/step - accuracy: 0.8928 - loss: 0.3298 - val_accuracy: 0.1724 - val_loss: 8.3163\nEpoch 87/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 48ms/step - accuracy: 0.9060 - loss: 0.2994 - val_accuracy: 0.1810 - val_loss: 7.1862\nEpoch 88/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 46ms/step - accuracy: 0.9022 - loss: 0.3020 - val_accuracy: 0.1940 - val_loss: 7.3386\nEpoch 89/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.9135 - loss: 0.2461 - val_accuracy: 0.1983 - val_loss: 7.0985\nEpoch 90/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 45ms/step - accuracy: 0.8990 - loss: 0.2972 - val_accuracy: 0.1767 - val_loss: 6.5192\nEpoch 91/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.9157 - loss: 0.2594 - val_accuracy: 0.2263 - val_loss: 6.2249\nEpoch 92/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 48ms/step - accuracy: 0.9132 - loss: 0.2611 - val_accuracy: 0.2263 - val_loss: 6.8590\nEpoch 93/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 46ms/step - accuracy: 0.9252 - loss: 0.2518 - val_accuracy: 0.2026 - val_loss: 6.7665\nEpoch 94/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.9208 - loss: 0.2612 - val_accuracy: 0.1509 - val_loss: 7.9143\nEpoch 95/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 45ms/step - accuracy: 0.9230 - loss: 0.2569 - val_accuracy: 0.1638 - val_loss: 8.3884\nEpoch 96/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 45ms/step - accuracy: 0.9002 - loss: 0.3403 - val_accuracy: 0.1272 - val_loss: 7.9247\nEpoch 97/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 46ms/step - accuracy: 0.8952 - loss: 0.3464 - val_accuracy: 0.2371 - val_loss: 5.6017\nEpoch 98/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 46ms/step - accuracy: 0.9091 - loss: 0.2749 - val_accuracy: 0.1315 - val_loss: 8.4071\nEpoch 99/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 45ms/step - accuracy: 0.8716 - loss: 0.4023 - val_accuracy: 0.1616 - val_loss: 6.9386\nEpoch 100/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 45ms/step - accuracy: 0.9157 - loss: 0.2774 - val_accuracy: 0.1444 - val_loss: 7.6295\n\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 304ms/step - accuracy: 0.1538 - loss: 8.4687\nTest accuracy: 0.16525423526763916\n","output_type":"stream"}]},{"cell_type":"code","source":"history3 = efficientnetb0_model.fit(train_generator, epochs=100, validation_data=(x_val, y_val))\nloss, accuracy = efficientnetb0_model.evaluate(x_test,y_test_encoded)\nprint(f\"Test accuracy: {accuracy}\")","metadata":{"execution":{"iopub.status.busy":"2024-09-10T08:45:56.461516Z","iopub.execute_input":"2024-09-10T08:45:56.461878Z","iopub.status.idle":"2024-09-10T08:58:10.560700Z","shell.execute_reply.started":"2024-09-10T08:45:56.461844Z","shell.execute_reply":"2024-09-10T08:58:10.559718Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"Epoch 1/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 418ms/step - accuracy: 0.1645 - loss: 3.0224 - val_accuracy: 0.2004 - val_loss: 3.1326\nEpoch 2/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 48ms/step - accuracy: 0.3958 - loss: 2.1157 - val_accuracy: 0.1961 - val_loss: 3.4478\nEpoch 3/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.5171 - loss: 1.6223 - val_accuracy: 0.2177 - val_loss: 3.4283\nEpoch 4/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 50ms/step - accuracy: 0.5923 - loss: 1.3174 - val_accuracy: 0.2522 - val_loss: 3.2805\nEpoch 5/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 48ms/step - accuracy: 0.6608 - loss: 1.1043 - val_accuracy: 0.2522 - val_loss: 3.4011\nEpoch 6/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.6857 - loss: 1.0168 - val_accuracy: 0.2672 - val_loss: 3.6802\nEpoch 7/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 48ms/step - accuracy: 0.7413 - loss: 0.8372 - val_accuracy: 0.2134 - val_loss: 4.3046\nEpoch 8/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.7474 - loss: 0.8272 - val_accuracy: 0.2672 - val_loss: 4.0665\nEpoch 9/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.7627 - loss: 0.7802 - val_accuracy: 0.2155 - val_loss: 3.8916\nEpoch 10/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 49ms/step - accuracy: 0.8038 - loss: 0.6455 - val_accuracy: 0.2241 - val_loss: 4.3516\nEpoch 11/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 48ms/step - accuracy: 0.8080 - loss: 0.6436 - val_accuracy: 0.2478 - val_loss: 3.8410\nEpoch 12/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 48ms/step - accuracy: 0.8243 - loss: 0.5500 - val_accuracy: 0.2522 - val_loss: 4.2091\nEpoch 13/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.8254 - loss: 0.5556 - val_accuracy: 0.2371 - val_loss: 4.4276\nEpoch 14/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.8444 - loss: 0.5159 - val_accuracy: 0.2522 - val_loss: 4.7634\nEpoch 15/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 48ms/step - accuracy: 0.8539 - loss: 0.4819 - val_accuracy: 0.2220 - val_loss: 4.9835\nEpoch 16/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.8713 - loss: 0.4252 - val_accuracy: 0.2435 - val_loss: 4.9598\nEpoch 17/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.8557 - loss: 0.4438 - val_accuracy: 0.2672 - val_loss: 4.9402\nEpoch 18/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.8752 - loss: 0.3931 - val_accuracy: 0.2888 - val_loss: 4.1401\nEpoch 19/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.8691 - loss: 0.4035 - val_accuracy: 0.2478 - val_loss: 4.3070\nEpoch 20/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 49ms/step - accuracy: 0.8670 - loss: 0.4279 - val_accuracy: 0.2629 - val_loss: 4.4467\nEpoch 21/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 46ms/step - accuracy: 0.8877 - loss: 0.3666 - val_accuracy: 0.2371 - val_loss: 4.8730\nEpoch 22/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 46ms/step - accuracy: 0.8966 - loss: 0.3394 - val_accuracy: 0.2716 - val_loss: 4.7891\nEpoch 23/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 46ms/step - accuracy: 0.8926 - loss: 0.3806 - val_accuracy: 0.2435 - val_loss: 4.3525\nEpoch 24/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 46ms/step - accuracy: 0.8808 - loss: 0.3822 - val_accuracy: 0.2543 - val_loss: 5.1768\nEpoch 25/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 48ms/step - accuracy: 0.9092 - loss: 0.3076 - val_accuracy: 0.2349 - val_loss: 5.3675\nEpoch 26/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.9037 - loss: 0.3078 - val_accuracy: 0.2565 - val_loss: 5.3252\nEpoch 27/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.9076 - loss: 0.3037 - val_accuracy: 0.2371 - val_loss: 5.0996\nEpoch 28/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.9027 - loss: 0.3114 - val_accuracy: 0.2586 - val_loss: 4.7657\nEpoch 29/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 46ms/step - accuracy: 0.9044 - loss: 0.2943 - val_accuracy: 0.2953 - val_loss: 4.5824\nEpoch 30/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.9124 - loss: 0.2963 - val_accuracy: 0.2931 - val_loss: 5.1459\nEpoch 31/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 48ms/step - accuracy: 0.9167 - loss: 0.2595 - val_accuracy: 0.2608 - val_loss: 4.8971\nEpoch 32/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.9110 - loss: 0.3094 - val_accuracy: 0.2802 - val_loss: 4.5844\nEpoch 33/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 46ms/step - accuracy: 0.9024 - loss: 0.3309 - val_accuracy: 0.2565 - val_loss: 4.9116\nEpoch 34/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 46ms/step - accuracy: 0.9090 - loss: 0.2893 - val_accuracy: 0.2241 - val_loss: 5.2527\nEpoch 35/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 46ms/step - accuracy: 0.9077 - loss: 0.2941 - val_accuracy: 0.2823 - val_loss: 4.0405\nEpoch 36/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 48ms/step - accuracy: 0.9157 - loss: 0.2798 - val_accuracy: 0.2694 - val_loss: 5.3707\nEpoch 37/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.9154 - loss: 0.2721 - val_accuracy: 0.2414 - val_loss: 5.8945\nEpoch 38/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 48ms/step - accuracy: 0.9211 - loss: 0.2607 - val_accuracy: 0.2759 - val_loss: 4.7447\nEpoch 39/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.9143 - loss: 0.2843 - val_accuracy: 0.2629 - val_loss: 4.3947\nEpoch 40/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.9237 - loss: 0.2618 - val_accuracy: 0.2629 - val_loss: 5.2186\nEpoch 41/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 48ms/step - accuracy: 0.9314 - loss: 0.2216 - val_accuracy: 0.1961 - val_loss: 5.5540\nEpoch 42/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 46ms/step - accuracy: 0.9375 - loss: 0.2131 - val_accuracy: 0.2759 - val_loss: 5.1221\nEpoch 43/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.9240 - loss: 0.2607 - val_accuracy: 0.1875 - val_loss: 6.3130\nEpoch 44/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 46ms/step - accuracy: 0.9372 - loss: 0.2240 - val_accuracy: 0.2435 - val_loss: 5.7312\nEpoch 45/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.9354 - loss: 0.2289 - val_accuracy: 0.2392 - val_loss: 6.3531\nEpoch 46/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 48ms/step - accuracy: 0.9305 - loss: 0.2334 - val_accuracy: 0.2263 - val_loss: 6.0449\nEpoch 47/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 48ms/step - accuracy: 0.9362 - loss: 0.2153 - val_accuracy: 0.1940 - val_loss: 6.7683\nEpoch 48/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.9270 - loss: 0.2128 - val_accuracy: 0.2241 - val_loss: 6.3438\nEpoch 49/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.9320 - loss: 0.2262 - val_accuracy: 0.2586 - val_loss: 5.5431\nEpoch 50/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 48ms/step - accuracy: 0.9231 - loss: 0.2412 - val_accuracy: 0.2155 - val_loss: 6.0006\nEpoch 51/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.9222 - loss: 0.2460 - val_accuracy: 0.2759 - val_loss: 5.2407\nEpoch 52/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 48ms/step - accuracy: 0.9442 - loss: 0.2071 - val_accuracy: 0.2392 - val_loss: 5.9422\nEpoch 53/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 48ms/step - accuracy: 0.9312 - loss: 0.2192 - val_accuracy: 0.2392 - val_loss: 5.6881\nEpoch 54/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.9335 - loss: 0.2155 - val_accuracy: 0.2328 - val_loss: 6.2629\nEpoch 55/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 48ms/step - accuracy: 0.9394 - loss: 0.1923 - val_accuracy: 0.2694 - val_loss: 5.4926\nEpoch 56/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.9345 - loss: 0.2235 - val_accuracy: 0.2716 - val_loss: 5.2105\nEpoch 57/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 48ms/step - accuracy: 0.9564 - loss: 0.1507 - val_accuracy: 0.2759 - val_loss: 5.5947\nEpoch 58/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.9431 - loss: 0.1659 - val_accuracy: 0.2392 - val_loss: 5.5389\nEpoch 59/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.9364 - loss: 0.2174 - val_accuracy: 0.2478 - val_loss: 5.5022\nEpoch 60/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 49ms/step - accuracy: 0.9478 - loss: 0.1777 - val_accuracy: 0.2392 - val_loss: 6.1368\nEpoch 61/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 49ms/step - accuracy: 0.9449 - loss: 0.1842 - val_accuracy: 0.2716 - val_loss: 6.1904\nEpoch 62/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 51ms/step - accuracy: 0.9399 - loss: 0.2183 - val_accuracy: 0.2694 - val_loss: 6.0389\nEpoch 63/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 49ms/step - accuracy: 0.9453 - loss: 0.1936 - val_accuracy: 0.2780 - val_loss: 5.6010\nEpoch 64/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 49ms/step - accuracy: 0.9315 - loss: 0.2287 - val_accuracy: 0.2478 - val_loss: 5.8971\nEpoch 65/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.9505 - loss: 0.1646 - val_accuracy: 0.2091 - val_loss: 5.9510\nEpoch 66/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 48ms/step - accuracy: 0.9469 - loss: 0.2009 - val_accuracy: 0.2457 - val_loss: 5.9679\nEpoch 67/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.9475 - loss: 0.1828 - val_accuracy: 0.2392 - val_loss: 6.3240\nEpoch 68/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.9500 - loss: 0.1661 - val_accuracy: 0.1530 - val_loss: 9.4271\nEpoch 69/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 48ms/step - accuracy: 0.9469 - loss: 0.2013 - val_accuracy: 0.2263 - val_loss: 6.7290\nEpoch 70/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.9482 - loss: 0.1603 - val_accuracy: 0.2155 - val_loss: 7.4722\nEpoch 71/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 48ms/step - accuracy: 0.9412 - loss: 0.2150 - val_accuracy: 0.2522 - val_loss: 5.9557\nEpoch 72/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 48ms/step - accuracy: 0.9409 - loss: 0.1869 - val_accuracy: 0.2500 - val_loss: 5.6546\nEpoch 73/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 48ms/step - accuracy: 0.9487 - loss: 0.1633 - val_accuracy: 0.2220 - val_loss: 7.2430\nEpoch 74/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 48ms/step - accuracy: 0.9549 - loss: 0.1374 - val_accuracy: 0.2198 - val_loss: 7.5356\nEpoch 75/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.9338 - loss: 0.2138 - val_accuracy: 0.2543 - val_loss: 6.0172\nEpoch 76/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 48ms/step - accuracy: 0.9446 - loss: 0.1803 - val_accuracy: 0.2802 - val_loss: 5.7139\nEpoch 77/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 50ms/step - accuracy: 0.9445 - loss: 0.1926 - val_accuracy: 0.2716 - val_loss: 6.1530\nEpoch 78/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 48ms/step - accuracy: 0.9507 - loss: 0.1589 - val_accuracy: 0.1789 - val_loss: 7.9793\nEpoch 79/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.9582 - loss: 0.1305 - val_accuracy: 0.2823 - val_loss: 6.8104\nEpoch 80/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.9395 - loss: 0.1753 - val_accuracy: 0.2672 - val_loss: 5.7550\nEpoch 81/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.9506 - loss: 0.1686 - val_accuracy: 0.2565 - val_loss: 6.3603\nEpoch 82/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 48ms/step - accuracy: 0.9534 - loss: 0.1822 - val_accuracy: 0.2026 - val_loss: 6.9687\nEpoch 83/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 48ms/step - accuracy: 0.9525 - loss: 0.1605 - val_accuracy: 0.2543 - val_loss: 7.2578\nEpoch 84/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.9529 - loss: 0.1633 - val_accuracy: 0.2069 - val_loss: 8.6999\nEpoch 85/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.9501 - loss: 0.1658 - val_accuracy: 0.2134 - val_loss: 7.1788\nEpoch 86/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.9512 - loss: 0.1668 - val_accuracy: 0.2565 - val_loss: 6.2595\nEpoch 87/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 46ms/step - accuracy: 0.9553 - loss: 0.1451 - val_accuracy: 0.2371 - val_loss: 6.3680\nEpoch 88/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.9597 - loss: 0.1353 - val_accuracy: 0.2284 - val_loss: 6.3550\nEpoch 89/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.9603 - loss: 0.1377 - val_accuracy: 0.2694 - val_loss: 6.2848\nEpoch 90/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 46ms/step - accuracy: 0.9511 - loss: 0.1604 - val_accuracy: 0.2565 - val_loss: 6.3646\nEpoch 91/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 46ms/step - accuracy: 0.9475 - loss: 0.1725 - val_accuracy: 0.2284 - val_loss: 8.2379\nEpoch 92/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.9494 - loss: 0.1563 - val_accuracy: 0.2845 - val_loss: 5.5590\nEpoch 93/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.9535 - loss: 0.1453 - val_accuracy: 0.2780 - val_loss: 6.1582\nEpoch 94/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.9539 - loss: 0.1475 - val_accuracy: 0.2414 - val_loss: 7.2410\nEpoch 95/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 45ms/step - accuracy: 0.9652 - loss: 0.1188 - val_accuracy: 0.2457 - val_loss: 7.5142\nEpoch 96/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 46ms/step - accuracy: 0.9501 - loss: 0.1587 - val_accuracy: 0.2349 - val_loss: 7.8880\nEpoch 97/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 46ms/step - accuracy: 0.9561 - loss: 0.1561 - val_accuracy: 0.2672 - val_loss: 6.3398\nEpoch 98/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 46ms/step - accuracy: 0.9532 - loss: 0.1550 - val_accuracy: 0.2737 - val_loss: 6.0335\nEpoch 99/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 46ms/step - accuracy: 0.9626 - loss: 0.1233 - val_accuracy: 0.2004 - val_loss: 7.5521\nEpoch 100/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 45ms/step - accuracy: 0.9619 - loss: 0.1414 - val_accuracy: 0.2349 - val_loss: 6.5995\n\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 483ms/step - accuracy: 0.1996 - loss: 6.6797\nTest accuracy: 0.1906779706478119\n","output_type":"stream"}]},{"cell_type":"code","source":"history4 = vgg16_model.fit(train_generator, epochs=100, validation_data=(x_val, y_val))\nloss, accuracy = vgg16_model.evaluate(x_test,y_test_encoded)\nprint(f\"Test accuracy: {accuracy}\")","metadata":{"execution":{"iopub.status.busy":"2024-09-10T08:58:10.562112Z","iopub.execute_input":"2024-09-10T08:58:10.563149Z","iopub.status.idle":"2024-09-10T09:09:32.572957Z","shell.execute_reply.started":"2024-09-10T08:58:10.563101Z","shell.execute_reply":"2024-09-10T09:09:32.571984Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"Epoch 1/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 107ms/step - accuracy: 0.0388 - loss: 7.2183 - val_accuracy: 0.0409 - val_loss: 3.2963\nEpoch 2/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 52ms/step - accuracy: 0.0370 - loss: 3.2964 - val_accuracy: 0.0409 - val_loss: 3.2965\nEpoch 3/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 52ms/step - accuracy: 0.0306 - loss: 3.2962 - val_accuracy: 0.0237 - val_loss: 3.2961\nEpoch 4/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 52ms/step - accuracy: 0.0361 - loss: 3.2963 - val_accuracy: 0.0431 - val_loss: 3.2957\nEpoch 5/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 53ms/step - accuracy: 0.0320 - loss: 3.2961 - val_accuracy: 0.0237 - val_loss: 3.2960\nEpoch 6/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 52ms/step - accuracy: 0.0346 - loss: 3.2961 - val_accuracy: 0.0453 - val_loss: 3.2959\nEpoch 7/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 51ms/step - accuracy: 0.0326 - loss: 3.2961 - val_accuracy: 0.0237 - val_loss: 3.2963\nEpoch 8/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 51ms/step - accuracy: 0.0303 - loss: 3.2960 - val_accuracy: 0.0259 - val_loss: 3.2960\nEpoch 9/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 51ms/step - accuracy: 0.0406 - loss: 3.2960 - val_accuracy: 0.0237 - val_loss: 3.2960\nEpoch 10/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 53ms/step - accuracy: 0.0280 - loss: 3.2960 - val_accuracy: 0.0194 - val_loss: 3.2960\nEpoch 11/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 51ms/step - accuracy: 0.0369 - loss: 3.2959 - val_accuracy: 0.0366 - val_loss: 3.2958\nEpoch 12/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 52ms/step - accuracy: 0.0374 - loss: 3.2960 - val_accuracy: 0.0237 - val_loss: 3.2960\nEpoch 13/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 51ms/step - accuracy: 0.0365 - loss: 3.2960 - val_accuracy: 0.0194 - val_loss: 3.2959\nEpoch 14/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 52ms/step - accuracy: 0.0279 - loss: 3.2960 - val_accuracy: 0.0259 - val_loss: 3.2962\nEpoch 15/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 52ms/step - accuracy: 0.0404 - loss: 3.2961 - val_accuracy: 0.0453 - val_loss: 3.2959\nEpoch 16/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 51ms/step - accuracy: 0.0326 - loss: 3.2960 - val_accuracy: 0.0366 - val_loss: 3.2961\nEpoch 17/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 52ms/step - accuracy: 0.0358 - loss: 3.2961 - val_accuracy: 0.0366 - val_loss: 3.2963\nEpoch 18/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 51ms/step - accuracy: 0.0363 - loss: 3.2961 - val_accuracy: 0.0453 - val_loss: 3.2960\nEpoch 19/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 52ms/step - accuracy: 0.0336 - loss: 3.2959 - val_accuracy: 0.0237 - val_loss: 3.2961\nEpoch 20/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 51ms/step - accuracy: 0.0337 - loss: 3.2961 - val_accuracy: 0.0453 - val_loss: 3.2962\nEpoch 21/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 51ms/step - accuracy: 0.0322 - loss: 3.2960 - val_accuracy: 0.0453 - val_loss: 3.2960\nEpoch 22/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 51ms/step - accuracy: 0.0347 - loss: 3.2960 - val_accuracy: 0.0474 - val_loss: 3.2957\nEpoch 23/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 51ms/step - accuracy: 0.0307 - loss: 3.2961 - val_accuracy: 0.0453 - val_loss: 3.2956\nEpoch 24/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 53ms/step - accuracy: 0.0284 - loss: 3.2960 - val_accuracy: 0.0603 - val_loss: 3.2955\nEpoch 25/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 51ms/step - accuracy: 0.0339 - loss: 3.2960 - val_accuracy: 0.0776 - val_loss: 3.2954\nEpoch 26/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 51ms/step - accuracy: 0.0404 - loss: 3.2960 - val_accuracy: 0.0474 - val_loss: 3.2957\nEpoch 27/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 51ms/step - accuracy: 0.0342 - loss: 3.2960 - val_accuracy: 0.0345 - val_loss: 3.2957\nEpoch 28/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 51ms/step - accuracy: 0.0338 - loss: 3.2960 - val_accuracy: 0.0603 - val_loss: 3.2958\nEpoch 29/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 52ms/step - accuracy: 0.0304 - loss: 3.2961 - val_accuracy: 0.0237 - val_loss: 3.2959\nEpoch 30/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 51ms/step - accuracy: 0.0368 - loss: 3.2961 - val_accuracy: 0.0366 - val_loss: 3.2957\nEpoch 31/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 51ms/step - accuracy: 0.0336 - loss: 3.2960 - val_accuracy: 0.0259 - val_loss: 3.2957\nEpoch 32/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 51ms/step - accuracy: 0.0351 - loss: 3.2960 - val_accuracy: 0.0237 - val_loss: 3.2961\nEpoch 33/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 51ms/step - accuracy: 0.0336 - loss: 3.2960 - val_accuracy: 0.0259 - val_loss: 3.2958\nEpoch 34/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 53ms/step - accuracy: 0.0331 - loss: 3.2960 - val_accuracy: 0.0409 - val_loss: 3.2958\nEpoch 35/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 52ms/step - accuracy: 0.0305 - loss: 3.2961 - val_accuracy: 0.0409 - val_loss: 3.2956\nEpoch 36/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 51ms/step - accuracy: 0.0340 - loss: 3.2961 - val_accuracy: 0.0409 - val_loss: 3.2957\nEpoch 37/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 51ms/step - accuracy: 0.0335 - loss: 3.2961 - val_accuracy: 0.0539 - val_loss: 3.2957\nEpoch 38/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 51ms/step - accuracy: 0.0407 - loss: 3.2960 - val_accuracy: 0.0237 - val_loss: 3.2957\nEpoch 39/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 52ms/step - accuracy: 0.0320 - loss: 3.2960 - val_accuracy: 0.0453 - val_loss: 3.2958\nEpoch 40/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 51ms/step - accuracy: 0.0312 - loss: 3.2961 - val_accuracy: 0.0345 - val_loss: 3.2958\nEpoch 41/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 52ms/step - accuracy: 0.0377 - loss: 3.2960 - val_accuracy: 0.0431 - val_loss: 3.2957\nEpoch 42/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 52ms/step - accuracy: 0.0337 - loss: 3.2961 - val_accuracy: 0.0431 - val_loss: 3.2957\nEpoch 43/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 51ms/step - accuracy: 0.0361 - loss: 3.2960 - val_accuracy: 0.0323 - val_loss: 3.2957\nEpoch 44/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 52ms/step - accuracy: 0.0295 - loss: 3.2960 - val_accuracy: 0.0431 - val_loss: 3.2957\nEpoch 45/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 51ms/step - accuracy: 0.0342 - loss: 3.2960 - val_accuracy: 0.0237 - val_loss: 3.2956\nEpoch 46/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 51ms/step - accuracy: 0.0339 - loss: 3.2959 - val_accuracy: 0.0237 - val_loss: 3.2958\nEpoch 47/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 51ms/step - accuracy: 0.0338 - loss: 3.2960 - val_accuracy: 0.0323 - val_loss: 3.2959\nEpoch 48/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 53ms/step - accuracy: 0.0319 - loss: 3.2960 - val_accuracy: 0.0259 - val_loss: 3.2958\nEpoch 49/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 51ms/step - accuracy: 0.0368 - loss: 3.2960 - val_accuracy: 0.0474 - val_loss: 3.2957\nEpoch 50/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 51ms/step - accuracy: 0.0395 - loss: 3.2960 - val_accuracy: 0.0323 - val_loss: 3.2956\nEpoch 51/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 52ms/step - accuracy: 0.0286 - loss: 3.2961 - val_accuracy: 0.0474 - val_loss: 3.2958\nEpoch 52/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 51ms/step - accuracy: 0.0358 - loss: 3.2960 - val_accuracy: 0.0323 - val_loss: 3.2958\nEpoch 53/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 53ms/step - accuracy: 0.0340 - loss: 3.2960 - val_accuracy: 0.0237 - val_loss: 3.2959\nEpoch 54/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 51ms/step - accuracy: 0.0374 - loss: 3.2960 - val_accuracy: 0.0474 - val_loss: 3.2955\nEpoch 55/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 51ms/step - accuracy: 0.0387 - loss: 3.2960 - val_accuracy: 0.0474 - val_loss: 3.2957\nEpoch 56/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 51ms/step - accuracy: 0.0348 - loss: 3.2960 - val_accuracy: 0.0280 - val_loss: 3.2955\nEpoch 57/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 51ms/step - accuracy: 0.0422 - loss: 3.2959 - val_accuracy: 0.0409 - val_loss: 3.2958\nEpoch 58/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 53ms/step - accuracy: 0.0299 - loss: 3.2960 - val_accuracy: 0.0323 - val_loss: 3.2959\nEpoch 59/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 51ms/step - accuracy: 0.0374 - loss: 3.2960 - val_accuracy: 0.0453 - val_loss: 3.2957\nEpoch 60/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 51ms/step - accuracy: 0.0420 - loss: 3.2960 - val_accuracy: 0.0409 - val_loss: 3.2958\nEpoch 61/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 51ms/step - accuracy: 0.0329 - loss: 3.2960 - val_accuracy: 0.0259 - val_loss: 3.2959\nEpoch 62/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 51ms/step - accuracy: 0.0350 - loss: 3.2960 - val_accuracy: 0.0453 - val_loss: 3.2958\nEpoch 63/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 52ms/step - accuracy: 0.0369 - loss: 3.2960 - val_accuracy: 0.0539 - val_loss: 3.2955\nEpoch 64/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 51ms/step - accuracy: 0.0368 - loss: 3.2960 - val_accuracy: 0.0409 - val_loss: 3.2958\nEpoch 65/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 51ms/step - accuracy: 0.0340 - loss: 3.2960 - val_accuracy: 0.0539 - val_loss: 3.2957\nEpoch 66/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 51ms/step - accuracy: 0.0330 - loss: 3.2961 - val_accuracy: 0.0409 - val_loss: 3.2957\nEpoch 67/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 51ms/step - accuracy: 0.0300 - loss: 3.2961 - val_accuracy: 0.0409 - val_loss: 3.2958\nEpoch 68/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 53ms/step - accuracy: 0.0292 - loss: 3.2960 - val_accuracy: 0.0453 - val_loss: 3.2958\nEpoch 69/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 52ms/step - accuracy: 0.0301 - loss: 3.2960 - val_accuracy: 0.0366 - val_loss: 3.2957\nEpoch 70/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 51ms/step - accuracy: 0.0316 - loss: 3.2960 - val_accuracy: 0.0431 - val_loss: 3.2957\nEpoch 71/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 51ms/step - accuracy: 0.0357 - loss: 3.2960 - val_accuracy: 0.0409 - val_loss: 3.2962\nEpoch 72/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 52ms/step - accuracy: 0.0357 - loss: 3.2960 - val_accuracy: 0.0259 - val_loss: 3.2960\nEpoch 73/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 52ms/step - accuracy: 0.0396 - loss: 3.2960 - val_accuracy: 0.0409 - val_loss: 3.2960\nEpoch 74/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 51ms/step - accuracy: 0.0339 - loss: 3.2960 - val_accuracy: 0.0345 - val_loss: 3.2958\nEpoch 75/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 51ms/step - accuracy: 0.0347 - loss: 3.2960 - val_accuracy: 0.0776 - val_loss: 3.2958\nEpoch 76/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 51ms/step - accuracy: 0.0407 - loss: 3.2960 - val_accuracy: 0.0323 - val_loss: 3.2960\nEpoch 77/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 52ms/step - accuracy: 0.0342 - loss: 3.2961 - val_accuracy: 0.0323 - val_loss: 3.2962\nEpoch 78/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 51ms/step - accuracy: 0.0343 - loss: 3.2960 - val_accuracy: 0.0194 - val_loss: 3.2958\nEpoch 79/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 51ms/step - accuracy: 0.0320 - loss: 3.2960 - val_accuracy: 0.0453 - val_loss: 3.2958\nEpoch 80/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 52ms/step - accuracy: 0.0323 - loss: 3.2960 - val_accuracy: 0.0453 - val_loss: 3.2958\nEpoch 81/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 51ms/step - accuracy: 0.0310 - loss: 3.2960 - val_accuracy: 0.0431 - val_loss: 3.2959\nEpoch 82/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 53ms/step - accuracy: 0.0289 - loss: 3.2961 - val_accuracy: 0.0431 - val_loss: 3.2958\nEpoch 83/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 52ms/step - accuracy: 0.0423 - loss: 3.2960 - val_accuracy: 0.0431 - val_loss: 3.2958\nEpoch 84/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 51ms/step - accuracy: 0.0384 - loss: 3.2960 - val_accuracy: 0.0431 - val_loss: 3.2957\nEpoch 85/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 51ms/step - accuracy: 0.0341 - loss: 3.2960 - val_accuracy: 0.0474 - val_loss: 3.2957\nEpoch 86/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 51ms/step - accuracy: 0.0310 - loss: 3.2960 - val_accuracy: 0.0237 - val_loss: 3.2960\nEpoch 87/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 53ms/step - accuracy: 0.0323 - loss: 3.2960 - val_accuracy: 0.0366 - val_loss: 3.2960\nEpoch 88/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 51ms/step - accuracy: 0.0320 - loss: 3.2961 - val_accuracy: 0.0453 - val_loss: 3.2956\nEpoch 89/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 51ms/step - accuracy: 0.0374 - loss: 3.2959 - val_accuracy: 0.0388 - val_loss: 3.2956\nEpoch 90/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 51ms/step - accuracy: 0.0338 - loss: 3.2960 - val_accuracy: 0.0280 - val_loss: 3.2958\nEpoch 91/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 51ms/step - accuracy: 0.0273 - loss: 3.2961 - val_accuracy: 0.0280 - val_loss: 3.2959\nEpoch 92/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 53ms/step - accuracy: 0.0350 - loss: 3.2960 - val_accuracy: 0.0345 - val_loss: 3.2957\nEpoch 93/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 51ms/step - accuracy: 0.0314 - loss: 3.2960 - val_accuracy: 0.0194 - val_loss: 3.2959\nEpoch 94/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 51ms/step - accuracy: 0.0384 - loss: 3.2960 - val_accuracy: 0.0323 - val_loss: 3.2959\nEpoch 95/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 51ms/step - accuracy: 0.0361 - loss: 3.2961 - val_accuracy: 0.0280 - val_loss: 3.2959\nEpoch 96/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 51ms/step - accuracy: 0.0301 - loss: 3.2961 - val_accuracy: 0.0366 - val_loss: 3.2956\nEpoch 97/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 53ms/step - accuracy: 0.0388 - loss: 3.2960 - val_accuracy: 0.0323 - val_loss: 3.2958\nEpoch 98/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 52ms/step - accuracy: 0.0365 - loss: 3.2960 - val_accuracy: 0.0237 - val_loss: 3.2958\nEpoch 99/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 51ms/step - accuracy: 0.0343 - loss: 3.2961 - val_accuracy: 0.0366 - val_loss: 3.2960\nEpoch 100/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 52ms/step - accuracy: 0.0334 - loss: 3.2960 - val_accuracy: 0.0323 - val_loss: 3.2960\n\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 228ms/step - accuracy: 0.0271 - loss: 3.2955\nTest accuracy: 0.04237288236618042\n","output_type":"stream"}]},{"cell_type":"code","source":"from tensorflow.keras.applications import Xception,DenseNet121,VGG19,ResNet101,EfficientNetV2B0,MobileNetV3Small\n\n\ndef create_DenseNet121_model(input_shape, num_classes):\n    base_model = DenseNet121(weights='imagenet', include_top=False, input_shape=input_shape)\n    \n    model = Sequential()\n    model.add(base_model) \n    model.add(GlobalAveragePooling2D())  \n    model.add(Dense(1024, activation='relu'))  \n    model.add(Dense(num_classes, activation='softmax'))  \n\n    return model\n\nDensenet_model = create_DenseNet121_model(input_shape, num_classes)\nDensenet_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n\n\ndef create_vgg19_model(input_shape, num_classes):\n    base_model = VGG19(weights='imagenet', include_top=False, input_shape=input_shape)\n    \n    model = Sequential()\n    model.add(base_model)  \n    model.add(GlobalAveragePooling2D())  \n    model.add(Dense(1024, activation='relu'))  \n    model.add(Dense(num_classes, activation='softmax')) \n\n    return model\n\nvgg19_model = create_vgg19_model(input_shape, num_classes)\nvgg19_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n\ndef create_resnet101_model(input_shape, num_classes):\n    base_model = ResNet101(weights='imagenet', include_top=False, input_shape=input_shape)\n    \n    model = Sequential()\n    model.add(base_model)  \n    model.add(GlobalAveragePooling2D())  \n    model.add(Dense(1024, activation='relu'))  \n    model.add(Dense(num_classes, activation='softmax'))  \n\n    return model\n\nresnet101_model = create_resnet101_model(input_shape, num_classes)\nresnet101_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n\ndef create_efficientnetv2b0_model(input_shape, num_classes):\n    base_model = EfficientNetV2B0(weights='imagenet', include_top=False, input_shape=input_shape)\n    \n    model = Sequential()\n    model.add(base_model)  \n    model.add(GlobalAveragePooling2D()) \n    model.add(Dense(1024, activation='relu'))  \n    model.add(Dense(num_classes, activation='softmax'))  \n\n    return model\n\nefficientnetv2b0_model = create_efficientnetv2b0_model(input_shape, num_classes)\nefficientnetv2b0_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n\ndef create_mobilenetv3_model(input_shape, num_classes):\n    base_model = MobileNetV3Small(weights='imagenet', include_top=False, input_shape=input_shape)\n    \n    model = Sequential()\n    model.add(base_model)  \n    model.add(GlobalAveragePooling2D())  \n    model.add(Dense(1024, activation='relu')) \n    model.add(Dense(num_classes, activation='softmax'))  \n\n    return model\n\nmobilenetv3_model = create_mobilenetv3_model(input_shape, num_classes)\nmobilenetv3_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2024-09-10T09:21:57.663859Z","iopub.execute_input":"2024-09-10T09:21:57.664469Z","iopub.status.idle":"2024-09-10T09:22:17.151576Z","shell.execute_reply.started":"2024-09-10T09:21:57.664430Z","shell.execute_reply":"2024-09-10T09:22:17.150565Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet121_weights_tf_dim_ordering_tf_kernels_notop.h5\n\u001b[1m29084464/29084464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\nDownloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n\u001b[1m80134624/80134624\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 0us/step\nDownloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet101_weights_tf_dim_ordering_tf_kernels_notop.h5\n\u001b[1m171446536/171446536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 0us/step\nDownloading data from https://storage.googleapis.com/tensorflow/keras-applications/efficientnet_v2/efficientnetv2-b0_notop.h5\n\u001b[1m24274472/24274472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/applications/mobilenet_v3.py:449: UserWarning: `input_shape` is undefined or non-square, or `rows` is not 224. Weights for input shape (224, 224) will be loaded as the default.\n  return MobileNetV3(\n","output_type":"stream"},{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v3/weights_mobilenet_v3_small_224_1.0_float_no_top_v2.h5\n\u001b[1m4334752/4334752\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n","output_type":"stream"}]},{"cell_type":"code","source":"def create_simple_cnn(input_shape, num_classes):\n    model = tf.keras.models.Sequential([\n        tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n        tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n        tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n        tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n        tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n        tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n        tf.keras.layers.Flatten(),\n        tf.keras.layers.Dense(512, activation='relu'),\n        tf.keras.layers.Dense(num_classes, activation='softmax')\n    ])\n    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n    return model\n\nsimple_cnn = create_simple_cnn(input_shape, num_classes)","metadata":{"execution":{"iopub.status.busy":"2024-09-10T09:22:23.394115Z","iopub.execute_input":"2024-09-10T09:22:23.394534Z","iopub.status.idle":"2024-09-10T09:22:23.448366Z","shell.execute_reply.started":"2024-09-10T09:22:23.394494Z","shell.execute_reply":"2024-09-10T09:22:23.447503Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n","output_type":"stream"}]},{"cell_type":"code","source":"history5 = simple_cnn.fit(train_generator, epochs=100, validation_data=(x_val, y_val))\nloss, accuracy = simple_cnn.evaluate(x_test,y_test_encoded)\nprint(f\"Test accuracy: {accuracy}\")","metadata":{"execution":{"iopub.status.busy":"2024-09-10T09:22:23.978083Z","iopub.execute_input":"2024-09-10T09:22:23.978440Z","iopub.status.idle":"2024-09-10T09:31:09.588447Z","shell.execute_reply.started":"2024-09-10T09:22:23.978404Z","shell.execute_reply":"2024-09-10T09:31:09.587609Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"Epoch 1/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 69ms/step - accuracy: 0.0465 - loss: 16.5617 - val_accuracy: 0.0474 - val_loss: 3.2532\nEpoch 2/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 41ms/step - accuracy: 0.0465 - loss: 3.2633 - val_accuracy: 0.0216 - val_loss: 3.2977\nEpoch 3/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step - accuracy: 0.0390 - loss: 3.2947 - val_accuracy: 0.0259 - val_loss: 3.2902\nEpoch 4/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 41ms/step - accuracy: 0.0403 - loss: 3.2941 - val_accuracy: 0.0560 - val_loss: 3.2329\nEpoch 5/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step - accuracy: 0.0430 - loss: 3.2855 - val_accuracy: 0.0323 - val_loss: 3.2863\nEpoch 6/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step - accuracy: 0.0438 - loss: 3.2913 - val_accuracy: 0.0302 - val_loss: 3.2879\nEpoch 7/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 41ms/step - accuracy: 0.0436 - loss: 3.2873 - val_accuracy: 0.0409 - val_loss: 3.2846\nEpoch 8/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step - accuracy: 0.0475 - loss: 3.2877 - val_accuracy: 0.0216 - val_loss: 3.2912\nEpoch 9/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step - accuracy: 0.0374 - loss: 3.2873 - val_accuracy: 0.0237 - val_loss: 3.2901\nEpoch 10/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step - accuracy: 0.0515 - loss: 3.2750 - val_accuracy: 0.0431 - val_loss: 3.2313\nEpoch 11/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step - accuracy: 0.0637 - loss: 3.2122 - val_accuracy: 0.0496 - val_loss: 3.2258\nEpoch 12/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step - accuracy: 0.0681 - loss: 3.2167 - val_accuracy: 0.0582 - val_loss: 3.2077\nEpoch 13/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 41ms/step - accuracy: 0.0747 - loss: 3.2068 - val_accuracy: 0.0453 - val_loss: 3.2285\nEpoch 14/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 39ms/step - accuracy: 0.0858 - loss: 3.1626 - val_accuracy: 0.0668 - val_loss: 3.2608\nEpoch 15/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step - accuracy: 0.0847 - loss: 3.1833 - val_accuracy: 0.0776 - val_loss: 3.2056\nEpoch 16/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step - accuracy: 0.0960 - loss: 3.1235 - val_accuracy: 0.0647 - val_loss: 3.1712\nEpoch 17/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step - accuracy: 0.1006 - loss: 3.1141 - val_accuracy: 0.1078 - val_loss: 3.2137\nEpoch 18/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step - accuracy: 0.1155 - loss: 3.0775 - val_accuracy: 0.0970 - val_loss: 3.2386\nEpoch 19/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step - accuracy: 0.1106 - loss: 3.0585 - val_accuracy: 0.0905 - val_loss: 3.1929\nEpoch 20/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step - accuracy: 0.1300 - loss: 3.0232 - val_accuracy: 0.1056 - val_loss: 3.1937\nEpoch 21/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step - accuracy: 0.1401 - loss: 2.9754 - val_accuracy: 0.1034 - val_loss: 3.2849\nEpoch 22/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step - accuracy: 0.1381 - loss: 2.9887 - val_accuracy: 0.1185 - val_loss: 3.1541\nEpoch 23/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step - accuracy: 0.1606 - loss: 2.9253 - val_accuracy: 0.1272 - val_loss: 3.1709\nEpoch 24/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step - accuracy: 0.1703 - loss: 2.8970 - val_accuracy: 0.1315 - val_loss: 3.4443\nEpoch 25/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 39ms/step - accuracy: 0.1859 - loss: 2.8534 - val_accuracy: 0.1185 - val_loss: 3.2077\nEpoch 26/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step - accuracy: 0.1953 - loss: 2.8054 - val_accuracy: 0.1272 - val_loss: 3.1491\nEpoch 27/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step - accuracy: 0.2060 - loss: 2.7671 - val_accuracy: 0.1401 - val_loss: 3.3499\nEpoch 28/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step - accuracy: 0.1877 - loss: 2.7805 - val_accuracy: 0.1616 - val_loss: 3.1449\nEpoch 29/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step - accuracy: 0.2342 - loss: 2.7097 - val_accuracy: 0.1487 - val_loss: 3.2214\nEpoch 30/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 41ms/step - accuracy: 0.2327 - loss: 2.6321 - val_accuracy: 0.1746 - val_loss: 3.1042\nEpoch 31/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step - accuracy: 0.2344 - loss: 2.6204 - val_accuracy: 0.1573 - val_loss: 3.1994\nEpoch 32/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 41ms/step - accuracy: 0.2570 - loss: 2.5540 - val_accuracy: 0.1487 - val_loss: 3.2668\nEpoch 33/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step - accuracy: 0.2793 - loss: 2.5091 - val_accuracy: 0.1595 - val_loss: 3.3394\nEpoch 34/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step - accuracy: 0.2783 - loss: 2.4815 - val_accuracy: 0.1767 - val_loss: 3.2131\nEpoch 35/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 41ms/step - accuracy: 0.2785 - loss: 2.4878 - val_accuracy: 0.1509 - val_loss: 3.1483\nEpoch 36/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step - accuracy: 0.3049 - loss: 2.3529 - val_accuracy: 0.1767 - val_loss: 3.3005\nEpoch 37/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step - accuracy: 0.3043 - loss: 2.3866 - val_accuracy: 0.1681 - val_loss: 3.1249\nEpoch 38/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 41ms/step - accuracy: 0.3322 - loss: 2.3447 - val_accuracy: 0.1616 - val_loss: 3.1782\nEpoch 39/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step - accuracy: 0.3319 - loss: 2.2841 - val_accuracy: 0.1595 - val_loss: 3.3324\nEpoch 40/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step - accuracy: 0.3493 - loss: 2.2558 - val_accuracy: 0.1530 - val_loss: 3.2586\nEpoch 41/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step - accuracy: 0.3624 - loss: 2.2204 - val_accuracy: 0.1983 - val_loss: 3.4015\nEpoch 42/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step - accuracy: 0.3604 - loss: 2.1792 - val_accuracy: 0.2047 - val_loss: 3.3972\nEpoch 43/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step - accuracy: 0.3906 - loss: 2.0876 - val_accuracy: 0.1659 - val_loss: 3.3857\nEpoch 44/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 41ms/step - accuracy: 0.3917 - loss: 2.0793 - val_accuracy: 0.1724 - val_loss: 3.5329\nEpoch 45/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 41ms/step - accuracy: 0.4002 - loss: 2.0411 - val_accuracy: 0.1724 - val_loss: 3.2302\nEpoch 46/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step - accuracy: 0.4227 - loss: 2.0395 - val_accuracy: 0.1746 - val_loss: 3.2888\nEpoch 47/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step - accuracy: 0.4332 - loss: 1.9795 - val_accuracy: 0.1767 - val_loss: 3.4232\nEpoch 48/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step - accuracy: 0.4403 - loss: 1.9192 - val_accuracy: 0.1875 - val_loss: 3.5447\nEpoch 49/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 39ms/step - accuracy: 0.4493 - loss: 1.9478 - val_accuracy: 0.1746 - val_loss: 3.9140\nEpoch 50/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step - accuracy: 0.4616 - loss: 1.8348 - val_accuracy: 0.1724 - val_loss: 3.9447\nEpoch 51/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 39ms/step - accuracy: 0.4590 - loss: 1.8187 - val_accuracy: 0.1638 - val_loss: 3.5822\nEpoch 52/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step - accuracy: 0.5013 - loss: 1.7327 - val_accuracy: 0.1853 - val_loss: 3.8010\nEpoch 53/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 41ms/step - accuracy: 0.4791 - loss: 1.8023 - val_accuracy: 0.1379 - val_loss: 3.9939\nEpoch 54/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step - accuracy: 0.4964 - loss: 1.7312 - val_accuracy: 0.1573 - val_loss: 4.0807\nEpoch 55/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step - accuracy: 0.4931 - loss: 1.7206 - val_accuracy: 0.1552 - val_loss: 3.9708\nEpoch 56/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step - accuracy: 0.4993 - loss: 1.6871 - val_accuracy: 0.2047 - val_loss: 3.7792\nEpoch 57/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 41ms/step - accuracy: 0.5150 - loss: 1.6609 - val_accuracy: 0.1875 - val_loss: 4.1193\nEpoch 58/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 39ms/step - accuracy: 0.5400 - loss: 1.6036 - val_accuracy: 0.1530 - val_loss: 3.8420\nEpoch 59/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 41ms/step - accuracy: 0.5312 - loss: 1.5898 - val_accuracy: 0.1983 - val_loss: 3.9904\nEpoch 60/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step - accuracy: 0.5239 - loss: 1.6409 - val_accuracy: 0.2069 - val_loss: 3.8587\nEpoch 61/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 41ms/step - accuracy: 0.5390 - loss: 1.5696 - val_accuracy: 0.1983 - val_loss: 4.0747\nEpoch 62/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step - accuracy: 0.5716 - loss: 1.4900 - val_accuracy: 0.2026 - val_loss: 3.9204\nEpoch 63/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step - accuracy: 0.5884 - loss: 1.4153 - val_accuracy: 0.2004 - val_loss: 3.9821\nEpoch 64/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step - accuracy: 0.5635 - loss: 1.4748 - val_accuracy: 0.1961 - val_loss: 4.0465\nEpoch 65/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 42ms/step - accuracy: 0.5739 - loss: 1.4423 - val_accuracy: 0.1832 - val_loss: 4.4967\nEpoch 66/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step - accuracy: 0.5896 - loss: 1.4088 - val_accuracy: 0.1853 - val_loss: 4.6186\nEpoch 67/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 39ms/step - accuracy: 0.5878 - loss: 1.3989 - val_accuracy: 0.2026 - val_loss: 4.1702\nEpoch 68/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 39ms/step - accuracy: 0.6056 - loss: 1.3104 - val_accuracy: 0.1875 - val_loss: 4.3892\nEpoch 69/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 41ms/step - accuracy: 0.6063 - loss: 1.3728 - val_accuracy: 0.1918 - val_loss: 4.1702\nEpoch 70/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 39ms/step - accuracy: 0.6198 - loss: 1.3146 - val_accuracy: 0.2091 - val_loss: 4.1456\nEpoch 71/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 41ms/step - accuracy: 0.5991 - loss: 1.3249 - val_accuracy: 0.2112 - val_loss: 4.5476\nEpoch 72/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step - accuracy: 0.6134 - loss: 1.3153 - val_accuracy: 0.1832 - val_loss: 4.7185\nEpoch 73/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 39ms/step - accuracy: 0.6149 - loss: 1.3015 - val_accuracy: 0.1875 - val_loss: 4.2411\nEpoch 74/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step - accuracy: 0.6170 - loss: 1.3085 - val_accuracy: 0.1918 - val_loss: 4.5930\nEpoch 75/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step - accuracy: 0.6480 - loss: 1.2024 - val_accuracy: 0.1810 - val_loss: 4.8108\nEpoch 76/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 41ms/step - accuracy: 0.6478 - loss: 1.2013 - val_accuracy: 0.1724 - val_loss: 4.6987\nEpoch 77/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step - accuracy: 0.6329 - loss: 1.2438 - val_accuracy: 0.2134 - val_loss: 4.5828\nEpoch 78/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 41ms/step - accuracy: 0.6513 - loss: 1.1434 - val_accuracy: 0.2026 - val_loss: 5.0067\nEpoch 79/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 41ms/step - accuracy: 0.6444 - loss: 1.1911 - val_accuracy: 0.1983 - val_loss: 4.9952\nEpoch 80/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 39ms/step - accuracy: 0.6723 - loss: 1.1308 - val_accuracy: 0.1875 - val_loss: 4.9620\nEpoch 81/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 39ms/step - accuracy: 0.6762 - loss: 1.0728 - val_accuracy: 0.2004 - val_loss: 4.8915\nEpoch 82/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step - accuracy: 0.6708 - loss: 1.1457 - val_accuracy: 0.2069 - val_loss: 5.0208\nEpoch 83/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 39ms/step - accuracy: 0.6748 - loss: 1.1236 - val_accuracy: 0.1940 - val_loss: 4.5293\nEpoch 84/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 41ms/step - accuracy: 0.6703 - loss: 1.1180 - val_accuracy: 0.2004 - val_loss: 4.9017\nEpoch 85/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 39ms/step - accuracy: 0.6921 - loss: 1.0762 - val_accuracy: 0.2026 - val_loss: 5.1706\nEpoch 86/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step - accuracy: 0.6735 - loss: 1.0899 - val_accuracy: 0.1918 - val_loss: 5.0862\nEpoch 87/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step - accuracy: 0.7065 - loss: 0.9774 - val_accuracy: 0.2220 - val_loss: 5.5426\nEpoch 88/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step - accuracy: 0.6791 - loss: 1.0277 - val_accuracy: 0.1853 - val_loss: 5.0432\nEpoch 89/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 39ms/step - accuracy: 0.6951 - loss: 1.0218 - val_accuracy: 0.2026 - val_loss: 5.5030\nEpoch 90/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 41ms/step - accuracy: 0.7119 - loss: 0.9985 - val_accuracy: 0.2112 - val_loss: 5.2324\nEpoch 91/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step - accuracy: 0.7114 - loss: 0.9744 - val_accuracy: 0.1897 - val_loss: 5.2886\nEpoch 92/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 41ms/step - accuracy: 0.7250 - loss: 0.9260 - val_accuracy: 0.1897 - val_loss: 5.8342\nEpoch 93/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step - accuracy: 0.7147 - loss: 0.9769 - val_accuracy: 0.1681 - val_loss: 5.4228\nEpoch 94/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step - accuracy: 0.6956 - loss: 1.0021 - val_accuracy: 0.1961 - val_loss: 5.2655\nEpoch 95/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 39ms/step - accuracy: 0.7084 - loss: 0.9783 - val_accuracy: 0.1853 - val_loss: 5.6740\nEpoch 96/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 41ms/step - accuracy: 0.7157 - loss: 0.9978 - val_accuracy: 0.2004 - val_loss: 5.1874\nEpoch 97/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step - accuracy: 0.7199 - loss: 0.9270 - val_accuracy: 0.1940 - val_loss: 5.4500\nEpoch 98/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 39ms/step - accuracy: 0.7375 - loss: 0.9104 - val_accuracy: 0.2026 - val_loss: 6.0956\nEpoch 99/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step - accuracy: 0.7035 - loss: 1.0068 - val_accuracy: 0.1940 - val_loss: 6.0183\nEpoch 100/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step - accuracy: 0.7415 - loss: 0.8855 - val_accuracy: 0.1746 - val_loss: 5.7750\n\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - accuracy: 0.1907 - loss: 6.6918\nTest accuracy: 0.14830508828163147\n","output_type":"stream"}]},{"cell_type":"code","source":"history7 = Densenet_model.fit(train_generator, epochs=100, validation_data=(x_val, y_val))\nloss, accuracy = Densenet_model.evaluate(x_test,y_test_encoded)\nprint(f\"Test accuracy: {accuracy}\")","metadata":{"execution":{"iopub.status.busy":"2024-09-10T09:31:09.590086Z","iopub.execute_input":"2024-09-10T09:31:09.590396Z","iopub.status.idle":"2024-09-10T09:45:13.440199Z","shell.execute_reply.started":"2024-09-10T09:31:09.590363Z","shell.execute_reply":"2024-09-10T09:45:13.439117Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"Epoch 1/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m181s\u001b[0m 573ms/step - accuracy: 0.0906 - loss: 3.4974 - val_accuracy: 0.0603 - val_loss: 4.9516\nEpoch 2/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 51ms/step - accuracy: 0.1870 - loss: 2.7899 - val_accuracy: 0.1703 - val_loss: 3.7490\nEpoch 3/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 49ms/step - accuracy: 0.2504 - loss: 2.5101 - val_accuracy: 0.1379 - val_loss: 3.4867\nEpoch 4/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 53ms/step - accuracy: 0.2917 - loss: 2.3707 - val_accuracy: 0.1466 - val_loss: 4.1146\nEpoch 5/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 49ms/step - accuracy: 0.3135 - loss: 2.3360 - val_accuracy: 0.1185 - val_loss: 5.5377\nEpoch 6/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 50ms/step - accuracy: 0.3499 - loss: 2.1764 - val_accuracy: 0.2091 - val_loss: 4.1675\nEpoch 7/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 51ms/step - accuracy: 0.4208 - loss: 1.9408 - val_accuracy: 0.1315 - val_loss: 154.1733\nEpoch 8/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 52ms/step - accuracy: 0.4356 - loss: 1.8516 - val_accuracy: 0.1616 - val_loss: 13.2098\nEpoch 9/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 52ms/step - accuracy: 0.4675 - loss: 1.8526 - val_accuracy: 0.0323 - val_loss: 542.9761\nEpoch 10/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 51ms/step - accuracy: 0.4693 - loss: 1.7544 - val_accuracy: 0.0991 - val_loss: 25.9935\nEpoch 11/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 51ms/step - accuracy: 0.4677 - loss: 1.7433 - val_accuracy: 0.2004 - val_loss: 4.0071\nEpoch 12/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 50ms/step - accuracy: 0.5522 - loss: 1.4254 - val_accuracy: 0.2112 - val_loss: 4.2609\nEpoch 13/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 52ms/step - accuracy: 0.5835 - loss: 1.3286 - val_accuracy: 0.2435 - val_loss: 3.9927\nEpoch 14/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 53ms/step - accuracy: 0.6372 - loss: 1.1684 - val_accuracy: 0.2672 - val_loss: 4.0810\nEpoch 15/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 51ms/step - accuracy: 0.6527 - loss: 1.1346 - val_accuracy: 0.2500 - val_loss: 3.7442\nEpoch 16/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 50ms/step - accuracy: 0.6584 - loss: 1.0885 - val_accuracy: 0.2586 - val_loss: 3.4347\nEpoch 17/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 51ms/step - accuracy: 0.7107 - loss: 0.9378 - val_accuracy: 0.2026 - val_loss: 5.2334\nEpoch 18/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 50ms/step - accuracy: 0.7273 - loss: 0.8865 - val_accuracy: 0.2026 - val_loss: 5.2454\nEpoch 19/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 54ms/step - accuracy: 0.7451 - loss: 0.8064 - val_accuracy: 0.2565 - val_loss: 4.1594\nEpoch 20/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 52ms/step - accuracy: 0.7667 - loss: 0.7689 - val_accuracy: 0.2263 - val_loss: 4.8151\nEpoch 21/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 49ms/step - accuracy: 0.7473 - loss: 0.7793 - val_accuracy: 0.2629 - val_loss: 4.2100\nEpoch 22/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 49ms/step - accuracy: 0.7662 - loss: 0.7693 - val_accuracy: 0.2716 - val_loss: 3.8779\nEpoch 23/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 52ms/step - accuracy: 0.8008 - loss: 0.6372 - val_accuracy: 0.2953 - val_loss: 4.1013\nEpoch 24/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 50ms/step - accuracy: 0.7848 - loss: 0.6496 - val_accuracy: 0.2004 - val_loss: 6.1506\nEpoch 25/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 51ms/step - accuracy: 0.7979 - loss: 0.6353 - val_accuracy: 0.2759 - val_loss: 4.0990\nEpoch 26/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 51ms/step - accuracy: 0.8321 - loss: 0.5226 - val_accuracy: 0.2026 - val_loss: 5.3998\nEpoch 27/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 49ms/step - accuracy: 0.8237 - loss: 0.5731 - val_accuracy: 0.2651 - val_loss: 4.8935\nEpoch 28/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 53ms/step - accuracy: 0.8375 - loss: 0.4895 - val_accuracy: 0.2155 - val_loss: 6.3384\nEpoch 29/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 52ms/step - accuracy: 0.8322 - loss: 0.5009 - val_accuracy: 0.2737 - val_loss: 4.4281\nEpoch 30/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 51ms/step - accuracy: 0.8530 - loss: 0.4401 - val_accuracy: 0.2241 - val_loss: 6.3403\nEpoch 31/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 50ms/step - accuracy: 0.8492 - loss: 0.4805 - val_accuracy: 0.2435 - val_loss: 5.5294\nEpoch 32/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 50ms/step - accuracy: 0.8623 - loss: 0.4093 - val_accuracy: 0.2608 - val_loss: 5.6378\nEpoch 33/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 54ms/step - accuracy: 0.8518 - loss: 0.4815 - val_accuracy: 0.2672 - val_loss: 5.8911\nEpoch 34/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 51ms/step - accuracy: 0.8735 - loss: 0.3986 - val_accuracy: 0.2953 - val_loss: 5.5042\nEpoch 35/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 51ms/step - accuracy: 0.8744 - loss: 0.3840 - val_accuracy: 0.2435 - val_loss: 6.0597\nEpoch 36/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 50ms/step - accuracy: 0.8886 - loss: 0.3366 - val_accuracy: 0.2435 - val_loss: 5.7539\nEpoch 37/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 52ms/step - accuracy: 0.8827 - loss: 0.3923 - val_accuracy: 0.2651 - val_loss: 6.6880\nEpoch 38/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 53ms/step - accuracy: 0.8762 - loss: 0.3849 - val_accuracy: 0.2069 - val_loss: 6.4709\nEpoch 39/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 50ms/step - accuracy: 0.8822 - loss: 0.3741 - val_accuracy: 0.2909 - val_loss: 5.4948\nEpoch 40/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 51ms/step - accuracy: 0.9043 - loss: 0.3069 - val_accuracy: 0.2974 - val_loss: 5.5554\nEpoch 41/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 52ms/step - accuracy: 0.8999 - loss: 0.2992 - val_accuracy: 0.2694 - val_loss: 5.3340\nEpoch 42/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 51ms/step - accuracy: 0.9131 - loss: 0.2722 - val_accuracy: 0.2866 - val_loss: 4.5660\nEpoch 43/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 52ms/step - accuracy: 0.8950 - loss: 0.3022 - val_accuracy: 0.2392 - val_loss: 7.2571\nEpoch 44/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 52ms/step - accuracy: 0.8995 - loss: 0.3165 - val_accuracy: 0.3060 - val_loss: 5.3210\nEpoch 45/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 51ms/step - accuracy: 0.9000 - loss: 0.3138 - val_accuracy: 0.2543 - val_loss: 6.4341\nEpoch 46/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 53ms/step - accuracy: 0.9072 - loss: 0.2802 - val_accuracy: 0.2759 - val_loss: 5.5620\nEpoch 47/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 54ms/step - accuracy: 0.9157 - loss: 0.2642 - val_accuracy: 0.2909 - val_loss: 5.4451\nEpoch 48/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 51ms/step - accuracy: 0.9079 - loss: 0.2779 - val_accuracy: 0.2608 - val_loss: 6.7795\nEpoch 49/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 52ms/step - accuracy: 0.9117 - loss: 0.2849 - val_accuracy: 0.2953 - val_loss: 6.0015\nEpoch 50/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 51ms/step - accuracy: 0.9252 - loss: 0.2402 - val_accuracy: 0.2543 - val_loss: 5.6868\nEpoch 51/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 51ms/step - accuracy: 0.9124 - loss: 0.2645 - val_accuracy: 0.2220 - val_loss: 6.7337\nEpoch 52/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 52ms/step - accuracy: 0.8985 - loss: 0.3188 - val_accuracy: 0.2198 - val_loss: 8.4196\nEpoch 53/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 49ms/step - accuracy: 0.9168 - loss: 0.2617 - val_accuracy: 0.2478 - val_loss: 7.0177\nEpoch 54/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 53ms/step - accuracy: 0.9148 - loss: 0.2602 - val_accuracy: 0.2974 - val_loss: 6.3021\nEpoch 55/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 52ms/step - accuracy: 0.9292 - loss: 0.2092 - val_accuracy: 0.2651 - val_loss: 6.4715\nEpoch 56/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 51ms/step - accuracy: 0.9249 - loss: 0.2147 - val_accuracy: 0.2349 - val_loss: 6.6110\nEpoch 57/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 53ms/step - accuracy: 0.9135 - loss: 0.2615 - val_accuracy: 0.2909 - val_loss: 5.6625\nEpoch 58/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 51ms/step - accuracy: 0.9308 - loss: 0.2206 - val_accuracy: 0.2866 - val_loss: 6.5099\nEpoch 59/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 53ms/step - accuracy: 0.9196 - loss: 0.2593 - val_accuracy: 0.2845 - val_loss: 6.4965\nEpoch 60/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 51ms/step - accuracy: 0.9207 - loss: 0.2238 - val_accuracy: 0.3319 - val_loss: 5.4810\nEpoch 61/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 51ms/step - accuracy: 0.9422 - loss: 0.1795 - val_accuracy: 0.2284 - val_loss: 7.1932\nEpoch 62/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 54ms/step - accuracy: 0.9324 - loss: 0.2140 - val_accuracy: 0.2737 - val_loss: 6.7167\nEpoch 63/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 50ms/step - accuracy: 0.9254 - loss: 0.2290 - val_accuracy: 0.2284 - val_loss: 8.5202\nEpoch 64/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 51ms/step - accuracy: 0.9151 - loss: 0.2634 - val_accuracy: 0.2780 - val_loss: 6.0307\nEpoch 65/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 52ms/step - accuracy: 0.9444 - loss: 0.1732 - val_accuracy: 0.2888 - val_loss: 6.1407\nEpoch 66/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 50ms/step - accuracy: 0.9356 - loss: 0.2007 - val_accuracy: 0.2155 - val_loss: 7.4057\nEpoch 67/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 54ms/step - accuracy: 0.9237 - loss: 0.2321 - val_accuracy: 0.2004 - val_loss: 13.0596\nEpoch 68/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 51ms/step - accuracy: 0.9382 - loss: 0.1850 - val_accuracy: 0.2823 - val_loss: 7.2289\nEpoch 69/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 52ms/step - accuracy: 0.9485 - loss: 0.1644 - val_accuracy: 0.2543 - val_loss: 6.9711\nEpoch 70/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 53ms/step - accuracy: 0.9438 - loss: 0.1843 - val_accuracy: 0.2759 - val_loss: 7.7664\nEpoch 71/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 52ms/step - accuracy: 0.9313 - loss: 0.2206 - val_accuracy: 0.2500 - val_loss: 7.7002\nEpoch 72/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 53ms/step - accuracy: 0.9363 - loss: 0.1875 - val_accuracy: 0.2845 - val_loss: 7.3553\nEpoch 73/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 52ms/step - accuracy: 0.9533 - loss: 0.1436 - val_accuracy: 0.2457 - val_loss: 8.6892\nEpoch 74/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 51ms/step - accuracy: 0.9354 - loss: 0.1908 - val_accuracy: 0.2672 - val_loss: 9.2848\nEpoch 75/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 51ms/step - accuracy: 0.9359 - loss: 0.1839 - val_accuracy: 0.2716 - val_loss: 6.6146\nEpoch 76/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 52ms/step - accuracy: 0.9290 - loss: 0.2480 - val_accuracy: 0.2802 - val_loss: 7.0748\nEpoch 77/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 53ms/step - accuracy: 0.9364 - loss: 0.1890 - val_accuracy: 0.2974 - val_loss: 6.5881\nEpoch 78/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 50ms/step - accuracy: 0.9393 - loss: 0.1985 - val_accuracy: 0.2522 - val_loss: 8.0765\nEpoch 79/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 50ms/step - accuracy: 0.9538 - loss: 0.1499 - val_accuracy: 0.3233 - val_loss: 6.2389\nEpoch 80/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 51ms/step - accuracy: 0.9464 - loss: 0.1823 - val_accuracy: 0.2608 - val_loss: 6.9949\nEpoch 81/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 53ms/step - accuracy: 0.9529 - loss: 0.1358 - val_accuracy: 0.2478 - val_loss: 6.8500\nEpoch 82/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 50ms/step - accuracy: 0.9386 - loss: 0.2006 - val_accuracy: 0.2974 - val_loss: 6.7092\nEpoch 83/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 51ms/step - accuracy: 0.9469 - loss: 0.1690 - val_accuracy: 0.2284 - val_loss: 8.6210\nEpoch 84/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 49ms/step - accuracy: 0.9523 - loss: 0.1551 - val_accuracy: 0.2608 - val_loss: 7.0044\nEpoch 85/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 50ms/step - accuracy: 0.9407 - loss: 0.1903 - val_accuracy: 0.2500 - val_loss: 6.4912\nEpoch 86/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 53ms/step - accuracy: 0.9531 - loss: 0.1525 - val_accuracy: 0.2888 - val_loss: 7.1301\nEpoch 87/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 49ms/step - accuracy: 0.9574 - loss: 0.1335 - val_accuracy: 0.2672 - val_loss: 7.7758\nEpoch 88/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 52ms/step - accuracy: 0.9450 - loss: 0.1873 - val_accuracy: 0.2931 - val_loss: 6.8668\nEpoch 89/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 52ms/step - accuracy: 0.9450 - loss: 0.1671 - val_accuracy: 0.2909 - val_loss: 5.7185\nEpoch 90/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 50ms/step - accuracy: 0.9539 - loss: 0.1568 - val_accuracy: 0.2823 - val_loss: 8.0991\nEpoch 91/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 54ms/step - accuracy: 0.9716 - loss: 0.0886 - val_accuracy: 0.2435 - val_loss: 9.1813\nEpoch 92/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 51ms/step - accuracy: 0.9446 - loss: 0.1828 - val_accuracy: 0.2414 - val_loss: 8.0854\nEpoch 93/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 52ms/step - accuracy: 0.9495 - loss: 0.1635 - val_accuracy: 0.2974 - val_loss: 6.8347\nEpoch 94/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 51ms/step - accuracy: 0.9612 - loss: 0.1277 - val_accuracy: 0.2629 - val_loss: 6.3691\nEpoch 95/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 49ms/step - accuracy: 0.9661 - loss: 0.1029 - val_accuracy: 0.2694 - val_loss: 7.2696\nEpoch 96/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 52ms/step - accuracy: 0.9556 - loss: 0.1443 - val_accuracy: 0.3168 - val_loss: 6.4495\nEpoch 97/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 51ms/step - accuracy: 0.9486 - loss: 0.1687 - val_accuracy: 0.2931 - val_loss: 6.0876\nEpoch 98/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 51ms/step - accuracy: 0.9560 - loss: 0.1390 - val_accuracy: 0.2371 - val_loss: 7.5090\nEpoch 99/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 50ms/step - accuracy: 0.9489 - loss: 0.1553 - val_accuracy: 0.2371 - val_loss: 7.2951\nEpoch 100/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 51ms/step - accuracy: 0.9486 - loss: 0.1580 - val_accuracy: 0.2759 - val_loss: 7.9539\n\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 943ms/step - accuracy: 0.2890 - loss: 7.5500\nTest accuracy: 0.2923728823661804\n","output_type":"stream"}]},{"cell_type":"code","source":"history8 = resnet101_model.fit(train_generator, epochs=100, validation_data=(x_val, y_val))\nloss, accuracy = resnet101_model.evaluate(x_test,y_test_encoded)\nprint(f\"Test accuracy: {accuracy}\")","metadata":{"execution":{"iopub.status.busy":"2024-09-10T09:45:13.441311Z","iopub.execute_input":"2024-09-10T09:45:13.441602Z","iopub.status.idle":"2024-09-10T10:06:24.132535Z","shell.execute_reply.started":"2024-09-10T09:45:13.441569Z","shell.execute_reply":"2024-09-10T10:06:24.131548Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"Epoch 1/100\n","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1725961606.991129     113 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'loop_add_subtract_fusion_54', 40 bytes spill stores, 40 bytes spill loads\nptxas warning : Registers are spilled to local memory in function 'loop_add_subtract_fusion_52', 40 bytes spill stores, 40 bytes spill loads\n\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 401ms/step - accuracy: 0.1109 - loss: 3.4853 - val_accuracy: 0.0474 - val_loss: 87.6521\nEpoch 2/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 90ms/step - accuracy: 0.2117 - loss: 2.7038 - val_accuracy: 0.1444 - val_loss: 4.4446\nEpoch 3/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 90ms/step - accuracy: 0.2765 - loss: 2.4850 - val_accuracy: 0.0453 - val_loss: 18041.2012\nEpoch 4/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 90ms/step - accuracy: 0.2756 - loss: 2.4877 - val_accuracy: 0.0797 - val_loss: 74.8945\nEpoch 5/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 89ms/step - accuracy: 0.3323 - loss: 2.2505 - val_accuracy: 0.1228 - val_loss: 4.9717\nEpoch 6/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 88ms/step - accuracy: 0.3730 - loss: 2.0991 - val_accuracy: 0.0647 - val_loss: 1382.1005\nEpoch 7/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 88ms/step - accuracy: 0.3879 - loss: 2.0076 - val_accuracy: 0.1724 - val_loss: 24.1358\nEpoch 8/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 89ms/step - accuracy: 0.4275 - loss: 1.8776 - val_accuracy: 0.0970 - val_loss: 395.0124\nEpoch 9/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 88ms/step - accuracy: 0.4581 - loss: 1.8216 - val_accuracy: 0.1185 - val_loss: 2300.9915\nEpoch 10/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 89ms/step - accuracy: 0.5027 - loss: 1.6850 - val_accuracy: 0.1616 - val_loss: 10.3499\nEpoch 11/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 89ms/step - accuracy: 0.5329 - loss: 1.5529 - val_accuracy: 0.0733 - val_loss: 65.8878\nEpoch 12/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 89ms/step - accuracy: 0.5466 - loss: 1.4415 - val_accuracy: 0.0647 - val_loss: 4.0991\nEpoch 13/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 89ms/step - accuracy: 0.3859 - loss: 2.0885 - val_accuracy: 0.0862 - val_loss: 5.7663\nEpoch 14/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 89ms/step - accuracy: 0.5180 - loss: 1.5817 - val_accuracy: 0.1272 - val_loss: 5.8771\nEpoch 15/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 89ms/step - accuracy: 0.5910 - loss: 1.3598 - val_accuracy: 0.1358 - val_loss: 5.8669\nEpoch 16/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 89ms/step - accuracy: 0.6365 - loss: 1.1971 - val_accuracy: 0.1056 - val_loss: 12.3507\nEpoch 17/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 89ms/step - accuracy: 0.6586 - loss: 1.1166 - val_accuracy: 0.1573 - val_loss: 5.9511\nEpoch 18/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 88ms/step - accuracy: 0.6881 - loss: 1.0134 - val_accuracy: 0.1703 - val_loss: 4.4791\nEpoch 19/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 88ms/step - accuracy: 0.7225 - loss: 0.9007 - val_accuracy: 0.1466 - val_loss: 5.7955\nEpoch 20/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 89ms/step - accuracy: 0.7183 - loss: 0.8855 - val_accuracy: 0.1810 - val_loss: 5.4203\nEpoch 21/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 88ms/step - accuracy: 0.7406 - loss: 0.7854 - val_accuracy: 0.1746 - val_loss: 5.7985\nEpoch 22/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 89ms/step - accuracy: 0.7748 - loss: 0.7388 - val_accuracy: 0.1250 - val_loss: 21.3458\nEpoch 23/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 89ms/step - accuracy: 0.7661 - loss: 0.7427 - val_accuracy: 0.1961 - val_loss: 6.4814\nEpoch 24/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 88ms/step - accuracy: 0.7901 - loss: 0.6827 - val_accuracy: 0.2392 - val_loss: 4.7331\nEpoch 25/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 89ms/step - accuracy: 0.7920 - loss: 0.6627 - val_accuracy: 0.1810 - val_loss: 6.7421\nEpoch 26/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 89ms/step - accuracy: 0.8058 - loss: 0.6257 - val_accuracy: 0.1853 - val_loss: 7.0379\nEpoch 27/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 89ms/step - accuracy: 0.8288 - loss: 0.5567 - val_accuracy: 0.2522 - val_loss: 5.6434\nEpoch 28/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 90ms/step - accuracy: 0.8176 - loss: 0.5678 - val_accuracy: 0.2349 - val_loss: 6.4467\nEpoch 29/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 89ms/step - accuracy: 0.8131 - loss: 0.5720 - val_accuracy: 0.1961 - val_loss: 5.7246\nEpoch 30/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 88ms/step - accuracy: 0.8336 - loss: 0.5497 - val_accuracy: 0.1595 - val_loss: 6.4559\nEpoch 31/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 90ms/step - accuracy: 0.8488 - loss: 0.4843 - val_accuracy: 0.2284 - val_loss: 4.9747\nEpoch 32/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 89ms/step - accuracy: 0.8768 - loss: 0.4049 - val_accuracy: 0.1595 - val_loss: 11.5636\nEpoch 33/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 89ms/step - accuracy: 0.8714 - loss: 0.4522 - val_accuracy: 0.1767 - val_loss: 8.9082\nEpoch 34/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 89ms/step - accuracy: 0.8708 - loss: 0.4100 - val_accuracy: 0.1659 - val_loss: 6.6279\nEpoch 35/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 88ms/step - accuracy: 0.8531 - loss: 0.4843 - val_accuracy: 0.1897 - val_loss: 7.6248\nEpoch 36/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 89ms/step - accuracy: 0.8691 - loss: 0.4113 - val_accuracy: 0.2328 - val_loss: 5.3130\nEpoch 37/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 89ms/step - accuracy: 0.8647 - loss: 0.4073 - val_accuracy: 0.1789 - val_loss: 7.9468\nEpoch 38/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 89ms/step - accuracy: 0.8800 - loss: 0.3729 - val_accuracy: 0.2328 - val_loss: 5.8596\nEpoch 39/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 89ms/step - accuracy: 0.8907 - loss: 0.3577 - val_accuracy: 0.1703 - val_loss: 7.8641\nEpoch 40/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 89ms/step - accuracy: 0.8785 - loss: 0.3935 - val_accuracy: 0.1897 - val_loss: 6.6425\nEpoch 41/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 89ms/step - accuracy: 0.8836 - loss: 0.3758 - val_accuracy: 0.1638 - val_loss: 6.7788\nEpoch 42/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 89ms/step - accuracy: 0.8629 - loss: 0.4416 - val_accuracy: 0.2047 - val_loss: 5.5476\nEpoch 43/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 88ms/step - accuracy: 0.8906 - loss: 0.3420 - val_accuracy: 0.1789 - val_loss: 8.8140\nEpoch 44/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 89ms/step - accuracy: 0.8875 - loss: 0.3442 - val_accuracy: 0.2716 - val_loss: 5.7725\nEpoch 45/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 89ms/step - accuracy: 0.8993 - loss: 0.3150 - val_accuracy: 0.2047 - val_loss: 7.5903\nEpoch 46/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 89ms/step - accuracy: 0.9043 - loss: 0.3019 - val_accuracy: 0.1638 - val_loss: 8.0495\nEpoch 47/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 89ms/step - accuracy: 0.8969 - loss: 0.3140 - val_accuracy: 0.2198 - val_loss: 6.7050\nEpoch 48/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 89ms/step - accuracy: 0.9015 - loss: 0.3273 - val_accuracy: 0.2069 - val_loss: 6.3186\nEpoch 49/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 88ms/step - accuracy: 0.8985 - loss: 0.3145 - val_accuracy: 0.1573 - val_loss: 8.3686\nEpoch 50/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 89ms/step - accuracy: 0.9073 - loss: 0.2935 - val_accuracy: 0.1853 - val_loss: 5.9744\nEpoch 51/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 90ms/step - accuracy: 0.9128 - loss: 0.2803 - val_accuracy: 0.2759 - val_loss: 5.3833\nEpoch 52/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 91ms/step - accuracy: 0.9191 - loss: 0.2549 - val_accuracy: 0.1853 - val_loss: 7.9484\nEpoch 53/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 89ms/step - accuracy: 0.9266 - loss: 0.2307 - val_accuracy: 0.2198 - val_loss: 5.7023\nEpoch 54/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 89ms/step - accuracy: 0.9246 - loss: 0.2377 - val_accuracy: 0.2069 - val_loss: 6.8001\nEpoch 55/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 90ms/step - accuracy: 0.9210 - loss: 0.2598 - val_accuracy: 0.2047 - val_loss: 6.2411\nEpoch 56/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 89ms/step - accuracy: 0.9209 - loss: 0.2393 - val_accuracy: 0.1832 - val_loss: 6.7527\nEpoch 57/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 89ms/step - accuracy: 0.9195 - loss: 0.2542 - val_accuracy: 0.1358 - val_loss: 7.8971\nEpoch 58/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 90ms/step - accuracy: 0.9281 - loss: 0.2348 - val_accuracy: 0.2586 - val_loss: 5.4887\nEpoch 59/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 89ms/step - accuracy: 0.9295 - loss: 0.2334 - val_accuracy: 0.2414 - val_loss: 6.5064\nEpoch 60/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 89ms/step - accuracy: 0.9383 - loss: 0.2040 - val_accuracy: 0.1940 - val_loss: 6.4782\nEpoch 61/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 89ms/step - accuracy: 0.9414 - loss: 0.1892 - val_accuracy: 0.2220 - val_loss: 6.0475\nEpoch 62/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 88ms/step - accuracy: 0.9244 - loss: 0.2464 - val_accuracy: 0.2543 - val_loss: 5.6844\nEpoch 63/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 89ms/step - accuracy: 0.9325 - loss: 0.2245 - val_accuracy: 0.1401 - val_loss: 11.6006\nEpoch 64/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 90ms/step - accuracy: 0.9313 - loss: 0.2092 - val_accuracy: 0.1509 - val_loss: 9.8546\nEpoch 65/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 92ms/step - accuracy: 0.9358 - loss: 0.2015 - val_accuracy: 0.2263 - val_loss: 7.3862\nEpoch 66/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 90ms/step - accuracy: 0.9301 - loss: 0.2347 - val_accuracy: 0.2328 - val_loss: 5.7102\nEpoch 67/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 91ms/step - accuracy: 0.9269 - loss: 0.2473 - val_accuracy: 0.1961 - val_loss: 7.9912\nEpoch 68/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 90ms/step - accuracy: 0.9326 - loss: 0.2175 - val_accuracy: 0.1897 - val_loss: 9.1074\nEpoch 69/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 89ms/step - accuracy: 0.9360 - loss: 0.2016 - val_accuracy: 0.1961 - val_loss: 8.4366\nEpoch 70/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 89ms/step - accuracy: 0.9444 - loss: 0.1742 - val_accuracy: 0.1983 - val_loss: 6.9001\nEpoch 71/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 89ms/step - accuracy: 0.9363 - loss: 0.1949 - val_accuracy: 0.1746 - val_loss: 9.5388\nEpoch 72/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 89ms/step - accuracy: 0.9411 - loss: 0.1779 - val_accuracy: 0.2435 - val_loss: 7.6492\nEpoch 73/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 88ms/step - accuracy: 0.9452 - loss: 0.1762 - val_accuracy: 0.2263 - val_loss: 7.6116\nEpoch 74/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 89ms/step - accuracy: 0.9333 - loss: 0.1812 - val_accuracy: 0.2263 - val_loss: 6.7384\nEpoch 75/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 89ms/step - accuracy: 0.9452 - loss: 0.1615 - val_accuracy: 0.1832 - val_loss: 9.4072\nEpoch 76/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 89ms/step - accuracy: 0.9456 - loss: 0.1702 - val_accuracy: 0.1530 - val_loss: 8.1152\nEpoch 77/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 89ms/step - accuracy: 0.9371 - loss: 0.1959 - val_accuracy: 0.2478 - val_loss: 7.8702\nEpoch 78/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 89ms/step - accuracy: 0.9373 - loss: 0.1970 - val_accuracy: 0.2414 - val_loss: 6.2890\nEpoch 79/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 89ms/step - accuracy: 0.9568 - loss: 0.1558 - val_accuracy: 0.2091 - val_loss: 7.0433\nEpoch 80/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 89ms/step - accuracy: 0.9561 - loss: 0.1365 - val_accuracy: 0.1983 - val_loss: 8.0855\nEpoch 81/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 89ms/step - accuracy: 0.9431 - loss: 0.1873 - val_accuracy: 0.2177 - val_loss: 8.2712\nEpoch 82/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 88ms/step - accuracy: 0.9421 - loss: 0.1734 - val_accuracy: 0.1466 - val_loss: 8.2250\nEpoch 83/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 88ms/step - accuracy: 0.9332 - loss: 0.1958 - val_accuracy: 0.1810 - val_loss: 9.6320\nEpoch 84/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 89ms/step - accuracy: 0.9494 - loss: 0.1527 - val_accuracy: 0.2306 - val_loss: 7.2969\nEpoch 85/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 88ms/step - accuracy: 0.9637 - loss: 0.1322 - val_accuracy: 0.2543 - val_loss: 6.6979\nEpoch 86/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 91ms/step - accuracy: 0.9632 - loss: 0.1197 - val_accuracy: 0.1638 - val_loss: 7.8159\nEpoch 87/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 88ms/step - accuracy: 0.9434 - loss: 0.1705 - val_accuracy: 0.1789 - val_loss: 7.0105\nEpoch 88/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 88ms/step - accuracy: 0.9506 - loss: 0.1803 - val_accuracy: 0.2478 - val_loss: 6.0584\nEpoch 89/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 89ms/step - accuracy: 0.9504 - loss: 0.1394 - val_accuracy: 0.2414 - val_loss: 7.8342\nEpoch 90/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 88ms/step - accuracy: 0.9549 - loss: 0.1423 - val_accuracy: 0.1746 - val_loss: 9.8034\nEpoch 91/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 88ms/step - accuracy: 0.9508 - loss: 0.1409 - val_accuracy: 0.2478 - val_loss: 7.2177\nEpoch 92/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 88ms/step - accuracy: 0.9502 - loss: 0.1736 - val_accuracy: 0.1875 - val_loss: 8.6277\nEpoch 93/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 88ms/step - accuracy: 0.9652 - loss: 0.1094 - val_accuracy: 0.2177 - val_loss: 7.7395\nEpoch 94/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 89ms/step - accuracy: 0.9438 - loss: 0.2003 - val_accuracy: 0.2349 - val_loss: 6.8229\nEpoch 95/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 89ms/step - accuracy: 0.9513 - loss: 0.1680 - val_accuracy: 0.2220 - val_loss: 6.9658\nEpoch 96/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 88ms/step - accuracy: 0.9554 - loss: 0.1490 - val_accuracy: 0.1897 - val_loss: 8.4186\nEpoch 97/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 88ms/step - accuracy: 0.9485 - loss: 0.1695 - val_accuracy: 0.2241 - val_loss: 7.8862\nEpoch 98/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 89ms/step - accuracy: 0.9607 - loss: 0.1238 - val_accuracy: 0.1832 - val_loss: 9.0291\nEpoch 99/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 88ms/step - accuracy: 0.9564 - loss: 0.1389 - val_accuracy: 0.2134 - val_loss: 6.8137\nEpoch 100/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 88ms/step - accuracy: 0.9620 - loss: 0.1347 - val_accuracy: 0.2457 - val_loss: 6.6389\n\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 353ms/step - accuracy: 0.2065 - loss: 7.3007\nTest accuracy: 0.20762711763381958\n","output_type":"stream"}]},{"cell_type":"code","source":"history10 = vgg19_model.fit(train_generator, epochs=100, validation_data=(x_val, y_val))\nloss, accuracy = vgg19_model.evaluate(x_test,y_test_encoded)\nprint(f\"Test accuracy: {accuracy}\")","metadata":{"execution":{"iopub.status.busy":"2024-09-10T10:06:24.134627Z","iopub.execute_input":"2024-09-10T10:06:24.134992Z","iopub.status.idle":"2024-09-10T10:20:09.190454Z","shell.execute_reply.started":"2024-09-10T10:06:24.134956Z","shell.execute_reply":"2024-09-10T10:20:09.189511Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stdout","text":"Epoch 1/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 91ms/step - accuracy: 0.0310 - loss: 6.2765 - val_accuracy: 0.0366 - val_loss: 3.2965\nEpoch 2/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 64ms/step - accuracy: 0.0401 - loss: 3.2964 - val_accuracy: 0.0409 - val_loss: 3.2964\nEpoch 3/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 65ms/step - accuracy: 0.0288 - loss: 3.2963 - val_accuracy: 0.0409 - val_loss: 3.2960\nEpoch 4/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 65ms/step - accuracy: 0.0396 - loss: 3.2960 - val_accuracy: 0.0323 - val_loss: 3.2956\nEpoch 5/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 65ms/step - accuracy: 0.0362 - loss: 3.2961 - val_accuracy: 0.0539 - val_loss: 3.2955\nEpoch 6/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 65ms/step - accuracy: 0.0351 - loss: 3.2959 - val_accuracy: 0.0539 - val_loss: 3.2954\nEpoch 7/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 65ms/step - accuracy: 0.0323 - loss: 3.2960 - val_accuracy: 0.0539 - val_loss: 3.2955\nEpoch 8/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 64ms/step - accuracy: 0.0347 - loss: 3.2961 - val_accuracy: 0.0431 - val_loss: 3.2958\nEpoch 9/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 64ms/step - accuracy: 0.0316 - loss: 3.2960 - val_accuracy: 0.0194 - val_loss: 3.2958\nEpoch 10/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 64ms/step - accuracy: 0.0304 - loss: 3.2961 - val_accuracy: 0.0194 - val_loss: 3.2959\nEpoch 11/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 64ms/step - accuracy: 0.0344 - loss: 3.2961 - val_accuracy: 0.0237 - val_loss: 3.2960\nEpoch 12/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 64ms/step - accuracy: 0.0333 - loss: 3.2960 - val_accuracy: 0.0194 - val_loss: 3.2959\nEpoch 13/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 64ms/step - accuracy: 0.0353 - loss: 3.2960 - val_accuracy: 0.0237 - val_loss: 3.2959\nEpoch 14/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 64ms/step - accuracy: 0.0255 - loss: 3.2961 - val_accuracy: 0.0237 - val_loss: 3.2960\nEpoch 15/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 65ms/step - accuracy: 0.0362 - loss: 3.2960 - val_accuracy: 0.0237 - val_loss: 3.2958\nEpoch 16/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 64ms/step - accuracy: 0.0397 - loss: 3.3257 - val_accuracy: 0.0453 - val_loss: 3.4318\nEpoch 17/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 65ms/step - accuracy: 0.0342 - loss: 4.5386 - val_accuracy: 0.0496 - val_loss: 3.2867\nEpoch 18/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 65ms/step - accuracy: 0.0312 - loss: 3.2987 - val_accuracy: 0.0474 - val_loss: 3.2950\nEpoch 19/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 65ms/step - accuracy: 0.0390 - loss: 3.2967 - val_accuracy: 0.0453 - val_loss: 3.2956\nEpoch 20/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 64ms/step - accuracy: 0.0376 - loss: 3.2962 - val_accuracy: 0.0259 - val_loss: 3.2960\nEpoch 21/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 64ms/step - accuracy: 0.0346 - loss: 3.2962 - val_accuracy: 0.0388 - val_loss: 3.2954\nEpoch 22/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 64ms/step - accuracy: 0.0390 - loss: 3.2961 - val_accuracy: 0.0237 - val_loss: 3.2960\nEpoch 23/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 64ms/step - accuracy: 0.0320 - loss: 3.2961 - val_accuracy: 0.0388 - val_loss: 3.2954\nEpoch 24/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 65ms/step - accuracy: 0.0260 - loss: 3.2961 - val_accuracy: 0.0345 - val_loss: 3.2945\nEpoch 25/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 64ms/step - accuracy: 0.0381 - loss: 3.2962 - val_accuracy: 0.0194 - val_loss: 3.2960\nEpoch 26/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 64ms/step - accuracy: 0.0315 - loss: 3.2961 - val_accuracy: 0.0194 - val_loss: 3.2961\nEpoch 27/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 65ms/step - accuracy: 0.0402 - loss: 3.2961 - val_accuracy: 0.0194 - val_loss: 3.2959\nEpoch 28/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 64ms/step - accuracy: 0.0337 - loss: 3.2961 - val_accuracy: 0.0237 - val_loss: 3.2964\nEpoch 29/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 64ms/step - accuracy: 0.0379 - loss: 3.2961 - val_accuracy: 0.0323 - val_loss: 3.2962\nEpoch 30/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 64ms/step - accuracy: 0.0315 - loss: 3.2961 - val_accuracy: 0.0388 - val_loss: 3.2960\nEpoch 31/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 64ms/step - accuracy: 0.0363 - loss: 3.2961 - val_accuracy: 0.0237 - val_loss: 3.2961\nEpoch 32/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 64ms/step - accuracy: 0.0392 - loss: 3.2960 - val_accuracy: 0.0366 - val_loss: 3.2962\nEpoch 33/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 64ms/step - accuracy: 0.0342 - loss: 3.2961 - val_accuracy: 0.0453 - val_loss: 3.2957\nEpoch 34/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 64ms/step - accuracy: 0.0293 - loss: 3.2961 - val_accuracy: 0.0431 - val_loss: 3.2959\nEpoch 35/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 65ms/step - accuracy: 0.0374 - loss: 3.2960 - val_accuracy: 0.0431 - val_loss: 3.2959\nEpoch 36/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 64ms/step - accuracy: 0.0353 - loss: 3.2960 - val_accuracy: 0.0431 - val_loss: 3.2958\nEpoch 37/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 64ms/step - accuracy: 0.0261 - loss: 3.2961 - val_accuracy: 0.0431 - val_loss: 3.2956\nEpoch 38/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 64ms/step - accuracy: 0.0340 - loss: 3.2959 - val_accuracy: 0.0409 - val_loss: 3.2960\nEpoch 39/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 65ms/step - accuracy: 0.0354 - loss: 3.2961 - val_accuracy: 0.0603 - val_loss: 3.2959\nEpoch 40/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 64ms/step - accuracy: 0.0371 - loss: 3.2960 - val_accuracy: 0.0323 - val_loss: 3.2957\nEpoch 41/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 64ms/step - accuracy: 0.0334 - loss: 3.2961 - val_accuracy: 0.0323 - val_loss: 3.2960\nEpoch 42/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 64ms/step - accuracy: 0.0288 - loss: 3.2959 - val_accuracy: 0.0323 - val_loss: 3.2957\nEpoch 43/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 64ms/step - accuracy: 0.0331 - loss: 3.2961 - val_accuracy: 0.0431 - val_loss: 3.2959\nEpoch 44/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 64ms/step - accuracy: 0.0408 - loss: 3.2960 - val_accuracy: 0.0323 - val_loss: 3.2958\nEpoch 45/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 64ms/step - accuracy: 0.0321 - loss: 3.2960 - val_accuracy: 0.0474 - val_loss: 3.2958\nEpoch 46/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 64ms/step - accuracy: 0.0308 - loss: 3.2960 - val_accuracy: 0.0280 - val_loss: 3.2959\nEpoch 47/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 64ms/step - accuracy: 0.0387 - loss: 3.2959 - val_accuracy: 0.0259 - val_loss: 3.2959\nEpoch 48/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 64ms/step - accuracy: 0.0334 - loss: 3.2960 - val_accuracy: 0.0259 - val_loss: 3.2958\nEpoch 49/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 64ms/step - accuracy: 0.0377 - loss: 3.2961 - val_accuracy: 0.0237 - val_loss: 3.2958\nEpoch 50/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 64ms/step - accuracy: 0.0314 - loss: 3.2960 - val_accuracy: 0.0431 - val_loss: 3.2958\nEpoch 51/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 65ms/step - accuracy: 0.0353 - loss: 3.2960 - val_accuracy: 0.0388 - val_loss: 3.2958\nEpoch 52/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 64ms/step - accuracy: 0.0352 - loss: 3.2960 - val_accuracy: 0.0474 - val_loss: 3.2956\nEpoch 53/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 64ms/step - accuracy: 0.0302 - loss: 3.2960 - val_accuracy: 0.0388 - val_loss: 3.2957\nEpoch 54/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 64ms/step - accuracy: 0.0286 - loss: 3.2960 - val_accuracy: 0.0453 - val_loss: 3.2955\nEpoch 55/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 64ms/step - accuracy: 0.0337 - loss: 3.2961 - val_accuracy: 0.0259 - val_loss: 3.2958\nEpoch 56/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 64ms/step - accuracy: 0.0373 - loss: 3.2960 - val_accuracy: 0.0776 - val_loss: 3.2955\nEpoch 57/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 64ms/step - accuracy: 0.0342 - loss: 3.2960 - val_accuracy: 0.0388 - val_loss: 3.2958\nEpoch 58/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 64ms/step - accuracy: 0.0339 - loss: 3.2960 - val_accuracy: 0.0237 - val_loss: 3.2957\nEpoch 59/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 64ms/step - accuracy: 0.0293 - loss: 3.2960 - val_accuracy: 0.0453 - val_loss: 3.2959\nEpoch 60/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 64ms/step - accuracy: 0.0291 - loss: 3.2961 - val_accuracy: 0.0237 - val_loss: 3.2957\nEpoch 61/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 64ms/step - accuracy: 0.0358 - loss: 3.2960 - val_accuracy: 0.0776 - val_loss: 3.2958\nEpoch 62/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 64ms/step - accuracy: 0.0304 - loss: 3.2960 - val_accuracy: 0.0237 - val_loss: 3.2961\nEpoch 63/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 64ms/step - accuracy: 0.0312 - loss: 3.2961 - val_accuracy: 0.0776 - val_loss: 3.2955\nEpoch 64/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 64ms/step - accuracy: 0.0363 - loss: 3.2960 - val_accuracy: 0.0237 - val_loss: 3.2957\nEpoch 65/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 64ms/step - accuracy: 0.0346 - loss: 3.2960 - val_accuracy: 0.0776 - val_loss: 3.2956\nEpoch 66/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 64ms/step - accuracy: 0.0317 - loss: 3.2960 - val_accuracy: 0.0539 - val_loss: 3.2956\nEpoch 67/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 64ms/step - accuracy: 0.0310 - loss: 3.2960 - val_accuracy: 0.0603 - val_loss: 3.2956\nEpoch 68/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 64ms/step - accuracy: 0.0329 - loss: 3.2960 - val_accuracy: 0.0259 - val_loss: 3.2955\nEpoch 69/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 64ms/step - accuracy: 0.0411 - loss: 3.2960 - val_accuracy: 0.0453 - val_loss: 3.2957\nEpoch 70/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 64ms/step - accuracy: 0.0344 - loss: 3.2960 - val_accuracy: 0.0453 - val_loss: 3.2956\nEpoch 71/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 64ms/step - accuracy: 0.0371 - loss: 3.2960 - val_accuracy: 0.0323 - val_loss: 3.2960\nEpoch 72/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 64ms/step - accuracy: 0.0275 - loss: 3.2960 - val_accuracy: 0.0603 - val_loss: 3.2959\nEpoch 73/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 64ms/step - accuracy: 0.0303 - loss: 3.2960 - val_accuracy: 0.0323 - val_loss: 3.2959\nEpoch 74/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 64ms/step - accuracy: 0.0307 - loss: 3.2960 - val_accuracy: 0.0431 - val_loss: 3.2958\nEpoch 75/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 64ms/step - accuracy: 0.0434 - loss: 3.2960 - val_accuracy: 0.0453 - val_loss: 3.2956\nEpoch 76/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 64ms/step - accuracy: 0.0281 - loss: 3.2960 - val_accuracy: 0.0237 - val_loss: 3.2958\nEpoch 77/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 64ms/step - accuracy: 0.0359 - loss: 3.2961 - val_accuracy: 0.0323 - val_loss: 3.2957\nEpoch 78/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 64ms/step - accuracy: 0.0371 - loss: 3.2960 - val_accuracy: 0.0280 - val_loss: 3.2957\nEpoch 79/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 64ms/step - accuracy: 0.0278 - loss: 3.2960 - val_accuracy: 0.0280 - val_loss: 3.2959\nEpoch 80/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 64ms/step - accuracy: 0.0332 - loss: 3.2960 - val_accuracy: 0.0280 - val_loss: 3.2958\nEpoch 81/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 64ms/step - accuracy: 0.0305 - loss: 3.2960 - val_accuracy: 0.0237 - val_loss: 3.2959\nEpoch 82/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 64ms/step - accuracy: 0.0286 - loss: 3.2960 - val_accuracy: 0.0280 - val_loss: 3.2957\nEpoch 83/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 64ms/step - accuracy: 0.0372 - loss: 3.2960 - val_accuracy: 0.0237 - val_loss: 3.2960\nEpoch 84/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 64ms/step - accuracy: 0.0433 - loss: 3.2960 - val_accuracy: 0.0453 - val_loss: 3.2960\nEpoch 85/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 64ms/step - accuracy: 0.0335 - loss: 3.2960 - val_accuracy: 0.0453 - val_loss: 3.2959\nEpoch 86/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 65ms/step - accuracy: 0.0300 - loss: 3.2960 - val_accuracy: 0.0453 - val_loss: 3.2959\nEpoch 87/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 64ms/step - accuracy: 0.0297 - loss: 3.2960 - val_accuracy: 0.0345 - val_loss: 3.2959\nEpoch 88/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 64ms/step - accuracy: 0.0284 - loss: 3.2961 - val_accuracy: 0.0259 - val_loss: 3.2959\nEpoch 89/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 64ms/step - accuracy: 0.0353 - loss: 3.2960 - val_accuracy: 0.0345 - val_loss: 3.2959\nEpoch 90/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 65ms/step - accuracy: 0.0393 - loss: 3.2960 - val_accuracy: 0.0237 - val_loss: 3.2962\nEpoch 91/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 64ms/step - accuracy: 0.0346 - loss: 3.2960 - val_accuracy: 0.0237 - val_loss: 3.2960\nEpoch 92/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 64ms/step - accuracy: 0.0317 - loss: 3.2960 - val_accuracy: 0.0259 - val_loss: 3.2958\nEpoch 93/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 64ms/step - accuracy: 0.0325 - loss: 3.2961 - val_accuracy: 0.0194 - val_loss: 3.2963\nEpoch 94/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 64ms/step - accuracy: 0.0322 - loss: 3.2960 - val_accuracy: 0.0237 - val_loss: 3.2959\nEpoch 95/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 64ms/step - accuracy: 0.0298 - loss: 3.2961 - val_accuracy: 0.0345 - val_loss: 3.2959\nEpoch 96/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 64ms/step - accuracy: 0.0334 - loss: 3.2960 - val_accuracy: 0.0237 - val_loss: 3.2959\nEpoch 97/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 64ms/step - accuracy: 0.0356 - loss: 3.2961 - val_accuracy: 0.0237 - val_loss: 3.2960\nEpoch 98/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 64ms/step - accuracy: 0.0328 - loss: 3.2960 - val_accuracy: 0.0194 - val_loss: 3.2957\nEpoch 99/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 64ms/step - accuracy: 0.0306 - loss: 3.2960 - val_accuracy: 0.0453 - val_loss: 3.2959\nEpoch 100/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 64ms/step - accuracy: 0.0277 - loss: 3.2961 - val_accuracy: 0.0453 - val_loss: 3.2961\n\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.0583 - loss: 3.2960  \nTest accuracy: 0.0381355918943882\n","output_type":"stream"}]},{"cell_type":"code","source":"history11 = efficientnetv2b0_model.fit(train_generator, epochs=100, validation_data=(x_val, y_val))\nloss, accuracy = efficientnetv2b0_model.evaluate(x_test,y_test_encoded)\nprint(f\"Test accuracy: {accuracy}\")","metadata":{"execution":{"iopub.status.busy":"2024-09-10T10:20:09.191885Z","iopub.execute_input":"2024-09-10T10:20:09.192288Z","iopub.status.idle":"2024-09-10T10:33:03.390919Z","shell.execute_reply.started":"2024-09-10T10:20:09.192242Z","shell.execute_reply":"2024-09-10T10:33:03.389983Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stdout","text":"Epoch 1/100\n\u001b[1m  1/122\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:06:45\u001b[0m 93s/step - accuracy: 0.0312 - loss: 3.2989","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1725963701.728731     114 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'loop_add_subtract_fusion_13', 20 bytes spill stores, 20 bytes spill loads\n\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 514ms/step - accuracy: 0.1711 - loss: 2.9383 - val_accuracy: 0.2134 - val_loss: 2.9462\nEpoch 2/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 48ms/step - accuracy: 0.3945 - loss: 2.0841 - val_accuracy: 0.2155 - val_loss: 3.1263\nEpoch 3/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.5051 - loss: 1.6213 - val_accuracy: 0.2134 - val_loss: 3.6846\nEpoch 4/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 48ms/step - accuracy: 0.5891 - loss: 1.3429 - val_accuracy: 0.2328 - val_loss: 3.3864\nEpoch 5/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.6517 - loss: 1.1294 - val_accuracy: 0.2371 - val_loss: 3.7363\nEpoch 6/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 48ms/step - accuracy: 0.6961 - loss: 0.9718 - val_accuracy: 0.2112 - val_loss: 3.9199\nEpoch 7/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 49ms/step - accuracy: 0.7356 - loss: 0.8630 - val_accuracy: 0.2198 - val_loss: 3.9075\nEpoch 8/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 50ms/step - accuracy: 0.7491 - loss: 0.7828 - val_accuracy: 0.2328 - val_loss: 4.4246\nEpoch 9/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 48ms/step - accuracy: 0.7883 - loss: 0.6812 - val_accuracy: 0.2134 - val_loss: 4.1631\nEpoch 10/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 48ms/step - accuracy: 0.8116 - loss: 0.5919 - val_accuracy: 0.2155 - val_loss: 4.5518\nEpoch 11/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.8354 - loss: 0.5388 - val_accuracy: 0.2414 - val_loss: 4.2447\nEpoch 12/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.8482 - loss: 0.4639 - val_accuracy: 0.2478 - val_loss: 4.5135\nEpoch 13/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 48ms/step - accuracy: 0.8472 - loss: 0.4774 - val_accuracy: 0.2414 - val_loss: 4.7461\nEpoch 14/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.8527 - loss: 0.4670 - val_accuracy: 0.2328 - val_loss: 4.4568\nEpoch 15/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 48ms/step - accuracy: 0.8608 - loss: 0.4453 - val_accuracy: 0.2284 - val_loss: 4.4751\nEpoch 16/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 48ms/step - accuracy: 0.8854 - loss: 0.3911 - val_accuracy: 0.2522 - val_loss: 4.6496\nEpoch 17/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 46ms/step - accuracy: 0.8651 - loss: 0.4146 - val_accuracy: 0.2672 - val_loss: 4.3134\nEpoch 18/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 49ms/step - accuracy: 0.9026 - loss: 0.3278 - val_accuracy: 0.2823 - val_loss: 4.5286\nEpoch 19/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.8833 - loss: 0.3690 - val_accuracy: 0.2435 - val_loss: 4.5946\nEpoch 20/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.8965 - loss: 0.3072 - val_accuracy: 0.2112 - val_loss: 5.7186\nEpoch 21/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 48ms/step - accuracy: 0.8970 - loss: 0.2995 - val_accuracy: 0.2478 - val_loss: 4.8987\nEpoch 22/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.8952 - loss: 0.2996 - val_accuracy: 0.2435 - val_loss: 5.1692\nEpoch 23/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 49ms/step - accuracy: 0.9000 - loss: 0.3315 - val_accuracy: 0.2737 - val_loss: 5.0066\nEpoch 24/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 48ms/step - accuracy: 0.8984 - loss: 0.3110 - val_accuracy: 0.2543 - val_loss: 5.1191\nEpoch 25/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 48ms/step - accuracy: 0.9063 - loss: 0.3159 - val_accuracy: 0.2866 - val_loss: 4.7204\nEpoch 26/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 48ms/step - accuracy: 0.9152 - loss: 0.2597 - val_accuracy: 0.2134 - val_loss: 5.4863\nEpoch 27/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 48ms/step - accuracy: 0.9274 - loss: 0.2354 - val_accuracy: 0.2414 - val_loss: 5.2532\nEpoch 28/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 50ms/step - accuracy: 0.9164 - loss: 0.2436 - val_accuracy: 0.2134 - val_loss: 5.8222\nEpoch 29/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 49ms/step - accuracy: 0.9090 - loss: 0.3002 - val_accuracy: 0.2328 - val_loss: 5.0273\nEpoch 30/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 48ms/step - accuracy: 0.9161 - loss: 0.2706 - val_accuracy: 0.2716 - val_loss: 4.7623\nEpoch 31/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.9352 - loss: 0.1998 - val_accuracy: 0.2716 - val_loss: 4.8203\nEpoch 32/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 49ms/step - accuracy: 0.9429 - loss: 0.1856 - val_accuracy: 0.2543 - val_loss: 5.7035\nEpoch 33/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 48ms/step - accuracy: 0.9284 - loss: 0.2312 - val_accuracy: 0.2845 - val_loss: 4.7990\nEpoch 34/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 49ms/step - accuracy: 0.9286 - loss: 0.2259 - val_accuracy: 0.2392 - val_loss: 5.2554\nEpoch 35/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 46ms/step - accuracy: 0.9455 - loss: 0.1826 - val_accuracy: 0.2349 - val_loss: 6.0489\nEpoch 36/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 48ms/step - accuracy: 0.9240 - loss: 0.2444 - val_accuracy: 0.2737 - val_loss: 5.1469\nEpoch 37/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.9376 - loss: 0.1996 - val_accuracy: 0.2737 - val_loss: 5.1123\nEpoch 38/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.9304 - loss: 0.2366 - val_accuracy: 0.2823 - val_loss: 5.2986\nEpoch 39/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 48ms/step - accuracy: 0.9321 - loss: 0.2354 - val_accuracy: 0.2565 - val_loss: 5.3880\nEpoch 40/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 46ms/step - accuracy: 0.9285 - loss: 0.2281 - val_accuracy: 0.2500 - val_loss: 6.1122\nEpoch 41/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 48ms/step - accuracy: 0.9414 - loss: 0.2079 - val_accuracy: 0.2586 - val_loss: 5.3039\nEpoch 42/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 49ms/step - accuracy: 0.9485 - loss: 0.1514 - val_accuracy: 0.2716 - val_loss: 6.1364\nEpoch 43/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.9285 - loss: 0.2337 - val_accuracy: 0.2306 - val_loss: 5.8123\nEpoch 44/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 50ms/step - accuracy: 0.9348 - loss: 0.1810 - val_accuracy: 0.2263 - val_loss: 6.1066\nEpoch 45/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.9302 - loss: 0.2219 - val_accuracy: 0.2134 - val_loss: 5.3684\nEpoch 46/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.9624 - loss: 0.1390 - val_accuracy: 0.2586 - val_loss: 6.4081\nEpoch 47/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 48ms/step - accuracy: 0.9558 - loss: 0.1455 - val_accuracy: 0.2284 - val_loss: 6.4773\nEpoch 48/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.9511 - loss: 0.1591 - val_accuracy: 0.2392 - val_loss: 6.5575\nEpoch 49/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 48ms/step - accuracy: 0.9523 - loss: 0.1360 - val_accuracy: 0.2177 - val_loss: 6.2278\nEpoch 50/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 46ms/step - accuracy: 0.9360 - loss: 0.2113 - val_accuracy: 0.2263 - val_loss: 7.0951\nEpoch 51/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.9263 - loss: 0.2383 - val_accuracy: 0.2435 - val_loss: 6.2654\nEpoch 52/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.9423 - loss: 0.2152 - val_accuracy: 0.1918 - val_loss: 7.4377\nEpoch 53/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.9502 - loss: 0.1653 - val_accuracy: 0.2392 - val_loss: 5.8723\nEpoch 54/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 49ms/step - accuracy: 0.9509 - loss: 0.1438 - val_accuracy: 0.2349 - val_loss: 6.4890\nEpoch 55/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.9485 - loss: 0.1753 - val_accuracy: 0.2457 - val_loss: 5.6711\nEpoch 56/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 46ms/step - accuracy: 0.9400 - loss: 0.1937 - val_accuracy: 0.2026 - val_loss: 6.4180\nEpoch 57/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.9549 - loss: 0.1395 - val_accuracy: 0.2198 - val_loss: 6.7359\nEpoch 58/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.9587 - loss: 0.1290 - val_accuracy: 0.2241 - val_loss: 6.2995\nEpoch 59/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 49ms/step - accuracy: 0.9549 - loss: 0.1592 - val_accuracy: 0.2392 - val_loss: 6.2805\nEpoch 60/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 48ms/step - accuracy: 0.9484 - loss: 0.1904 - val_accuracy: 0.2500 - val_loss: 5.4717\nEpoch 61/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 48ms/step - accuracy: 0.9561 - loss: 0.1542 - val_accuracy: 0.2263 - val_loss: 7.1646\nEpoch 62/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.9626 - loss: 0.1030 - val_accuracy: 0.2371 - val_loss: 6.5816\nEpoch 63/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.9587 - loss: 0.1284 - val_accuracy: 0.2241 - val_loss: 5.7261\nEpoch 64/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 48ms/step - accuracy: 0.9473 - loss: 0.1840 - val_accuracy: 0.2349 - val_loss: 5.7966\nEpoch 65/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 50ms/step - accuracy: 0.9509 - loss: 0.1597 - val_accuracy: 0.2629 - val_loss: 5.8385\nEpoch 66/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.9644 - loss: 0.1101 - val_accuracy: 0.2500 - val_loss: 5.6195\nEpoch 67/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 48ms/step - accuracy: 0.9567 - loss: 0.1388 - val_accuracy: 0.2134 - val_loss: 6.6946\nEpoch 68/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 46ms/step - accuracy: 0.9599 - loss: 0.1288 - val_accuracy: 0.2134 - val_loss: 6.3851\nEpoch 69/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 48ms/step - accuracy: 0.9530 - loss: 0.1688 - val_accuracy: 0.2565 - val_loss: 5.5164\nEpoch 70/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 50ms/step - accuracy: 0.9639 - loss: 0.1187 - val_accuracy: 0.2241 - val_loss: 6.0442\nEpoch 71/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 46ms/step - accuracy: 0.9689 - loss: 0.1176 - val_accuracy: 0.2284 - val_loss: 7.0258\nEpoch 72/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.9601 - loss: 0.1453 - val_accuracy: 0.2522 - val_loss: 6.1598\nEpoch 73/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.9504 - loss: 0.1688 - val_accuracy: 0.2047 - val_loss: 8.2876\nEpoch 74/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.9608 - loss: 0.1249 - val_accuracy: 0.2220 - val_loss: 6.8157\nEpoch 75/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 50ms/step - accuracy: 0.9574 - loss: 0.1319 - val_accuracy: 0.2651 - val_loss: 5.9862\nEpoch 76/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 48ms/step - accuracy: 0.9581 - loss: 0.1495 - val_accuracy: 0.2543 - val_loss: 6.2598\nEpoch 77/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.9557 - loss: 0.1369 - val_accuracy: 0.2435 - val_loss: 6.5911\nEpoch 78/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 48ms/step - accuracy: 0.9582 - loss: 0.1302 - val_accuracy: 0.2543 - val_loss: 5.9960\nEpoch 79/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.9501 - loss: 0.1503 - val_accuracy: 0.2478 - val_loss: 6.3390\nEpoch 80/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 48ms/step - accuracy: 0.9635 - loss: 0.1193 - val_accuracy: 0.2328 - val_loss: 6.5423\nEpoch 81/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.9636 - loss: 0.1090 - val_accuracy: 0.2371 - val_loss: 6.1058\nEpoch 82/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.9583 - loss: 0.1513 - val_accuracy: 0.2069 - val_loss: 6.7858\nEpoch 83/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.9575 - loss: 0.1422 - val_accuracy: 0.2672 - val_loss: 6.2676\nEpoch 84/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 46ms/step - accuracy: 0.9668 - loss: 0.1083 - val_accuracy: 0.2522 - val_loss: 6.5172\nEpoch 85/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 48ms/step - accuracy: 0.9746 - loss: 0.1029 - val_accuracy: 0.2371 - val_loss: 7.2047\nEpoch 86/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 49ms/step - accuracy: 0.9696 - loss: 0.1072 - val_accuracy: 0.2478 - val_loss: 6.9745\nEpoch 87/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 48ms/step - accuracy: 0.9532 - loss: 0.1800 - val_accuracy: 0.2414 - val_loss: 6.3667\nEpoch 88/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 48ms/step - accuracy: 0.9709 - loss: 0.1040 - val_accuracy: 0.2220 - val_loss: 6.6755\nEpoch 89/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.9614 - loss: 0.1248 - val_accuracy: 0.2198 - val_loss: 7.3448\nEpoch 90/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 45ms/step - accuracy: 0.9652 - loss: 0.1064 - val_accuracy: 0.2392 - val_loss: 6.8805\nEpoch 91/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 48ms/step - accuracy: 0.9696 - loss: 0.1077 - val_accuracy: 0.2629 - val_loss: 6.7250\nEpoch 92/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.9607 - loss: 0.1421 - val_accuracy: 0.2177 - val_loss: 7.4224\nEpoch 93/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 49ms/step - accuracy: 0.9656 - loss: 0.1277 - val_accuracy: 0.2198 - val_loss: 6.6973\nEpoch 94/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.9662 - loss: 0.1123 - val_accuracy: 0.2543 - val_loss: 6.0796\nEpoch 95/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 48ms/step - accuracy: 0.9682 - loss: 0.1076 - val_accuracy: 0.1875 - val_loss: 6.8539\nEpoch 96/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 49ms/step - accuracy: 0.9597 - loss: 0.1282 - val_accuracy: 0.2134 - val_loss: 6.5013\nEpoch 97/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.9692 - loss: 0.0931 - val_accuracy: 0.2328 - val_loss: 6.6463\nEpoch 98/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 49ms/step - accuracy: 0.9674 - loss: 0.1114 - val_accuracy: 0.2328 - val_loss: 7.2578\nEpoch 99/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 46ms/step - accuracy: 0.9626 - loss: 0.1201 - val_accuracy: 0.2500 - val_loss: 5.5250\nEpoch 100/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.9659 - loss: 0.1110 - val_accuracy: 0.2759 - val_loss: 5.9970\n\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 421ms/step - accuracy: 0.2200 - loss: 7.6262\nTest accuracy: 0.21610169112682343\n","output_type":"stream"}]},{"cell_type":"code","source":"history12 = mobilenetv3_model.fit(train_generator, epochs=100, validation_data=(x_val, y_val))\nloss, accuracy = mobilenetv3_model.evaluate(x_test,y_test_encoded)\nprint(f\"Test accuracy: {accuracy}\")","metadata":{"execution":{"iopub.status.busy":"2024-09-10T10:33:03.392217Z","iopub.execute_input":"2024-09-10T10:33:03.393176Z","iopub.status.idle":"2024-09-10T10:44:06.570881Z","shell.execute_reply.started":"2024-09-10T10:33:03.393130Z","shell.execute_reply":"2024-09-10T10:44:06.570008Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stdout","text":"Epoch 1/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 380ms/step - accuracy: 0.1172 - loss: 3.2439 - val_accuracy: 0.0862 - val_loss: 3.7983\nEpoch 2/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 45ms/step - accuracy: 0.2951 - loss: 2.4098 - val_accuracy: 0.1185 - val_loss: 3.3367\nEpoch 3/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 45ms/step - accuracy: 0.4095 - loss: 2.0133 - val_accuracy: 0.1444 - val_loss: 3.7234\nEpoch 4/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 46ms/step - accuracy: 0.4965 - loss: 1.6792 - val_accuracy: 0.1078 - val_loss: 5.5389\nEpoch 5/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 46ms/step - accuracy: 0.5553 - loss: 1.4858 - val_accuracy: 0.1336 - val_loss: 4.6666\nEpoch 6/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 45ms/step - accuracy: 0.6243 - loss: 1.2473 - val_accuracy: 0.1401 - val_loss: 4.1631\nEpoch 7/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 44ms/step - accuracy: 0.6751 - loss: 1.1010 - val_accuracy: 0.1315 - val_loss: 6.3327\nEpoch 8/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 44ms/step - accuracy: 0.6778 - loss: 1.0366 - val_accuracy: 0.1034 - val_loss: 5.6751\nEpoch 9/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 44ms/step - accuracy: 0.7259 - loss: 0.9057 - val_accuracy: 0.1422 - val_loss: 5.3233\nEpoch 10/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 45ms/step - accuracy: 0.7691 - loss: 0.7479 - val_accuracy: 0.1379 - val_loss: 5.9578\nEpoch 11/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 44ms/step - accuracy: 0.7790 - loss: 0.7270 - val_accuracy: 0.1466 - val_loss: 5.9767\nEpoch 12/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 43ms/step - accuracy: 0.7880 - loss: 0.6623 - val_accuracy: 0.1746 - val_loss: 5.5979\nEpoch 13/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 44ms/step - accuracy: 0.8081 - loss: 0.5979 - val_accuracy: 0.2112 - val_loss: 4.7230\nEpoch 14/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 44ms/step - accuracy: 0.8245 - loss: 0.5396 - val_accuracy: 0.1875 - val_loss: 5.1892\nEpoch 15/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 45ms/step - accuracy: 0.8398 - loss: 0.4991 - val_accuracy: 0.2263 - val_loss: 5.0549\nEpoch 16/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 44ms/step - accuracy: 0.8469 - loss: 0.4873 - val_accuracy: 0.2026 - val_loss: 5.1351\nEpoch 17/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 45ms/step - accuracy: 0.8773 - loss: 0.4138 - val_accuracy: 0.2328 - val_loss: 5.5820\nEpoch 18/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 44ms/step - accuracy: 0.8619 - loss: 0.4228 - val_accuracy: 0.2284 - val_loss: 6.0184\nEpoch 19/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 44ms/step - accuracy: 0.8742 - loss: 0.4001 - val_accuracy: 0.2069 - val_loss: 6.0444\nEpoch 20/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 45ms/step - accuracy: 0.8891 - loss: 0.3755 - val_accuracy: 0.2220 - val_loss: 6.5097\nEpoch 21/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 45ms/step - accuracy: 0.8833 - loss: 0.3622 - val_accuracy: 0.2672 - val_loss: 5.3062\nEpoch 22/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 45ms/step - accuracy: 0.8940 - loss: 0.3366 - val_accuracy: 0.2306 - val_loss: 5.8847\nEpoch 23/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 44ms/step - accuracy: 0.9099 - loss: 0.2825 - val_accuracy: 0.2414 - val_loss: 6.4592\nEpoch 24/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 45ms/step - accuracy: 0.9086 - loss: 0.2934 - val_accuracy: 0.2004 - val_loss: 6.6469\nEpoch 25/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 44ms/step - accuracy: 0.9088 - loss: 0.2915 - val_accuracy: 0.2306 - val_loss: 6.4095\nEpoch 26/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 46ms/step - accuracy: 0.9184 - loss: 0.2716 - val_accuracy: 0.2155 - val_loss: 6.0692\nEpoch 27/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 44ms/step - accuracy: 0.9185 - loss: 0.2656 - val_accuracy: 0.2457 - val_loss: 5.6122\nEpoch 28/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 44ms/step - accuracy: 0.9013 - loss: 0.2994 - val_accuracy: 0.2414 - val_loss: 5.7314\nEpoch 29/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 44ms/step - accuracy: 0.9180 - loss: 0.2765 - val_accuracy: 0.2414 - val_loss: 5.7223\nEpoch 30/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 45ms/step - accuracy: 0.9238 - loss: 0.2401 - val_accuracy: 0.2478 - val_loss: 5.7202\nEpoch 31/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 45ms/step - accuracy: 0.9280 - loss: 0.2432 - val_accuracy: 0.2522 - val_loss: 5.7055\nEpoch 32/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 46ms/step - accuracy: 0.9258 - loss: 0.2194 - val_accuracy: 0.2478 - val_loss: 5.7099\nEpoch 33/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 44ms/step - accuracy: 0.9253 - loss: 0.2337 - val_accuracy: 0.2392 - val_loss: 6.4048\nEpoch 34/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 45ms/step - accuracy: 0.9259 - loss: 0.2370 - val_accuracy: 0.2478 - val_loss: 7.2061\nEpoch 35/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 44ms/step - accuracy: 0.9318 - loss: 0.2140 - val_accuracy: 0.2220 - val_loss: 7.1674\nEpoch 36/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 46ms/step - accuracy: 0.9241 - loss: 0.2450 - val_accuracy: 0.2220 - val_loss: 6.9484\nEpoch 37/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 45ms/step - accuracy: 0.9219 - loss: 0.2631 - val_accuracy: 0.2241 - val_loss: 7.3287\nEpoch 38/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 44ms/step - accuracy: 0.9293 - loss: 0.2256 - val_accuracy: 0.2091 - val_loss: 7.2576\nEpoch 39/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.9398 - loss: 0.2050 - val_accuracy: 0.2414 - val_loss: 6.2360\nEpoch 40/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 45ms/step - accuracy: 0.9292 - loss: 0.1997 - val_accuracy: 0.2392 - val_loss: 6.6011\nEpoch 41/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 45ms/step - accuracy: 0.9351 - loss: 0.2332 - val_accuracy: 0.2500 - val_loss: 6.4080\nEpoch 42/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 46ms/step - accuracy: 0.9431 - loss: 0.1792 - val_accuracy: 0.2414 - val_loss: 6.8068\nEpoch 43/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 45ms/step - accuracy: 0.9357 - loss: 0.2100 - val_accuracy: 0.2909 - val_loss: 6.3711\nEpoch 44/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 44ms/step - accuracy: 0.9430 - loss: 0.1820 - val_accuracy: 0.2457 - val_loss: 7.4318\nEpoch 45/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 44ms/step - accuracy: 0.9446 - loss: 0.1820 - val_accuracy: 0.2263 - val_loss: 7.0413\nEpoch 46/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 44ms/step - accuracy: 0.9429 - loss: 0.1825 - val_accuracy: 0.1918 - val_loss: 7.4091\nEpoch 47/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 45ms/step - accuracy: 0.9571 - loss: 0.1273 - val_accuracy: 0.1918 - val_loss: 7.7965\nEpoch 48/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 46ms/step - accuracy: 0.9547 - loss: 0.1457 - val_accuracy: 0.2500 - val_loss: 6.5564\nEpoch 49/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.9402 - loss: 0.1974 - val_accuracy: 0.2823 - val_loss: 6.2767\nEpoch 50/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 48ms/step - accuracy: 0.9516 - loss: 0.1532 - val_accuracy: 0.2241 - val_loss: 7.1665\nEpoch 51/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.9473 - loss: 0.1580 - val_accuracy: 0.2155 - val_loss: 8.1300\nEpoch 52/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 46ms/step - accuracy: 0.9409 - loss: 0.1952 - val_accuracy: 0.1897 - val_loss: 7.4922\nEpoch 53/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.9563 - loss: 0.1382 - val_accuracy: 0.2478 - val_loss: 6.9823\nEpoch 54/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 46ms/step - accuracy: 0.9488 - loss: 0.1600 - val_accuracy: 0.2500 - val_loss: 6.2110\nEpoch 55/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.9492 - loss: 0.1690 - val_accuracy: 0.2586 - val_loss: 6.0105\nEpoch 56/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 48ms/step - accuracy: 0.9616 - loss: 0.1193 - val_accuracy: 0.2349 - val_loss: 7.3698\nEpoch 57/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.9508 - loss: 0.1553 - val_accuracy: 0.2737 - val_loss: 6.3683\nEpoch 58/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 46ms/step - accuracy: 0.9527 - loss: 0.1537 - val_accuracy: 0.2737 - val_loss: 7.6847\nEpoch 59/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.9505 - loss: 0.1566 - val_accuracy: 0.2392 - val_loss: 6.3044\nEpoch 60/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 46ms/step - accuracy: 0.9620 - loss: 0.1271 - val_accuracy: 0.2500 - val_loss: 6.8538\nEpoch 61/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.9645 - loss: 0.1059 - val_accuracy: 0.2349 - val_loss: 7.6292\nEpoch 62/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 46ms/step - accuracy: 0.9670 - loss: 0.1105 - val_accuracy: 0.2672 - val_loss: 6.7344\nEpoch 63/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 46ms/step - accuracy: 0.9634 - loss: 0.1296 - val_accuracy: 0.2586 - val_loss: 7.3380\nEpoch 64/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 45ms/step - accuracy: 0.9496 - loss: 0.1716 - val_accuracy: 0.2392 - val_loss: 7.4811\nEpoch 65/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 45ms/step - accuracy: 0.9496 - loss: 0.1562 - val_accuracy: 0.2414 - val_loss: 7.3084\nEpoch 66/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 44ms/step - accuracy: 0.9650 - loss: 0.1295 - val_accuracy: 0.2543 - val_loss: 7.2717\nEpoch 67/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 45ms/step - accuracy: 0.9666 - loss: 0.1070 - val_accuracy: 0.2500 - val_loss: 7.0912\nEpoch 68/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 46ms/step - accuracy: 0.9677 - loss: 0.1044 - val_accuracy: 0.2672 - val_loss: 6.2162\nEpoch 69/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 45ms/step - accuracy: 0.9588 - loss: 0.1371 - val_accuracy: 0.2392 - val_loss: 6.2115\nEpoch 70/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 48ms/step - accuracy: 0.9613 - loss: 0.1157 - val_accuracy: 0.2414 - val_loss: 6.9100\nEpoch 71/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 48ms/step - accuracy: 0.9562 - loss: 0.1248 - val_accuracy: 0.2349 - val_loss: 7.0783\nEpoch 72/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 46ms/step - accuracy: 0.9529 - loss: 0.1633 - val_accuracy: 0.2349 - val_loss: 7.3088\nEpoch 73/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.9565 - loss: 0.1399 - val_accuracy: 0.2435 - val_loss: 7.7844\nEpoch 74/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 45ms/step - accuracy: 0.9525 - loss: 0.1315 - val_accuracy: 0.2522 - val_loss: 7.1437\nEpoch 75/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.9738 - loss: 0.0899 - val_accuracy: 0.2198 - val_loss: 7.4860\nEpoch 76/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 44ms/step - accuracy: 0.9518 - loss: 0.1552 - val_accuracy: 0.2220 - val_loss: 7.3986\nEpoch 77/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 45ms/step - accuracy: 0.9617 - loss: 0.1276 - val_accuracy: 0.2565 - val_loss: 6.8382\nEpoch 78/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 46ms/step - accuracy: 0.9666 - loss: 0.1057 - val_accuracy: 0.2349 - val_loss: 7.3702\nEpoch 79/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 44ms/step - accuracy: 0.9680 - loss: 0.0895 - val_accuracy: 0.2220 - val_loss: 8.4729\nEpoch 80/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 46ms/step - accuracy: 0.9614 - loss: 0.1304 - val_accuracy: 0.2543 - val_loss: 7.9743\nEpoch 81/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 46ms/step - accuracy: 0.9700 - loss: 0.1099 - val_accuracy: 0.2608 - val_loss: 8.8884\nEpoch 82/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 45ms/step - accuracy: 0.9598 - loss: 0.1413 - val_accuracy: 0.2284 - val_loss: 7.7348\nEpoch 83/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 44ms/step - accuracy: 0.9674 - loss: 0.1061 - val_accuracy: 0.2435 - val_loss: 7.3224\nEpoch 84/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 44ms/step - accuracy: 0.9704 - loss: 0.1056 - val_accuracy: 0.2996 - val_loss: 7.0621\nEpoch 85/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 44ms/step - accuracy: 0.9662 - loss: 0.1099 - val_accuracy: 0.2414 - val_loss: 7.8301\nEpoch 86/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 45ms/step - accuracy: 0.9607 - loss: 0.1522 - val_accuracy: 0.2500 - val_loss: 8.0240\nEpoch 87/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.9802 - loss: 0.0808 - val_accuracy: 0.2328 - val_loss: 8.5724\nEpoch 88/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 46ms/step - accuracy: 0.9635 - loss: 0.1150 - val_accuracy: 0.2672 - val_loss: 6.5326\nEpoch 89/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.9733 - loss: 0.0980 - val_accuracy: 0.2672 - val_loss: 6.9926\nEpoch 90/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 45ms/step - accuracy: 0.9645 - loss: 0.1133 - val_accuracy: 0.2629 - val_loss: 6.5355\nEpoch 91/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 45ms/step - accuracy: 0.9661 - loss: 0.1048 - val_accuracy: 0.2608 - val_loss: 6.8582\nEpoch 92/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 44ms/step - accuracy: 0.9634 - loss: 0.1359 - val_accuracy: 0.2284 - val_loss: 7.3638\nEpoch 93/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 43ms/step - accuracy: 0.9664 - loss: 0.1041 - val_accuracy: 0.2392 - val_loss: 7.7633\nEpoch 94/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 45ms/step - accuracy: 0.9663 - loss: 0.1078 - val_accuracy: 0.2651 - val_loss: 6.9342\nEpoch 95/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 44ms/step - accuracy: 0.9684 - loss: 0.0983 - val_accuracy: 0.2435 - val_loss: 7.3379\nEpoch 96/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 43ms/step - accuracy: 0.9744 - loss: 0.0844 - val_accuracy: 0.2500 - val_loss: 7.5500\nEpoch 97/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 45ms/step - accuracy: 0.9701 - loss: 0.0907 - val_accuracy: 0.2500 - val_loss: 7.7329\nEpoch 98/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 44ms/step - accuracy: 0.9716 - loss: 0.1018 - val_accuracy: 0.2543 - val_loss: 7.0292\nEpoch 99/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 45ms/step - accuracy: 0.9715 - loss: 0.0923 - val_accuracy: 0.2565 - val_loss: 7.2331\nEpoch 100/100\n\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 44ms/step - accuracy: 0.9645 - loss: 0.1308 - val_accuracy: 0.2565 - val_loss: 6.8113\n\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 448ms/step - accuracy: 0.1986 - loss: 8.5916\nTest accuracy: 0.2118644118309021\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}