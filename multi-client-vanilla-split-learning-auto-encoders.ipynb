{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30648,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras import layers, models\n\n# Load and preprocess the MNIST dataset\n(x_train, _), (x_test, _) = tf.keras.datasets.mnist.load_data()\nx_train = x_train.astype('float32') / 255.0\nx_test = x_test.astype('float32') / 255.0\nx_train = tf.expand_dims(x_train, axis=-1)\nx_test = tf.expand_dims(x_test, axis=-1)\n\n# Define the autoencoder model\nautoencoder = models.Sequential([\n    # Encoder\n    layers.Input(shape=(28, 28, 1)),\n    layers.Conv2D(16, (3, 3), activation='relu', padding='same'),\n    layers.MaxPooling2D((2, 2), padding='same'),\n    layers.Conv2D(8, (3, 3), activation='relu', padding='same'),\n    layers.MaxPooling2D((2, 2), padding='same'),\n    \n    # Decoder\n    layers.Conv2DTranspose(8, (3, 3), activation='relu', padding='same'),\n    layers.UpSampling2D((2, 2)),\n    layers.Conv2DTranspose(16, (3, 3), activation='relu', padding='same'),\n    layers.UpSampling2D((2, 2)),\n    \n    # Output layer\n    layers.Conv2DTranspose(1, (3, 3), activation='sigmoid', padding='same')\n])\n\n# Compile the model\nautoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n\n# Train the model\nautoencoder.fit(x_train, x_train, epochs=50, batch_size=128, shuffle=True, validation_data=(x_test, x_test))\n\n# Save the model\nautoencoder.save('simple_autoencoder_model.h5')\n\n# Evaluate the model\nevaluation = autoencoder.evaluate(x_test, x_test, batch_size=128)\nprint(\"Evaluation Loss:\", evaluation)\n","metadata":{"execution":{"iopub.status.busy":"2024-02-27T18:23:17.691325Z","iopub.execute_input":"2024-02-27T18:23:17.691743Z","iopub.status.idle":"2024-02-27T18:25:13.904365Z","shell.execute_reply.started":"2024-02-27T18:23:17.691692Z","shell.execute_reply":"2024-02-27T18:25:13.903363Z"},"trusted":true},"execution_count":38,"outputs":[{"name":"stdout","text":"Epoch 1/50\n469/469 [==============================] - 4s 5ms/step - loss: 0.1512 - val_loss: 0.0902\nEpoch 2/50\n469/469 [==============================] - 2s 5ms/step - loss: 0.0862 - val_loss: 0.0817\nEpoch 3/50\n469/469 [==============================] - 2s 5ms/step - loss: 0.0808 - val_loss: 0.0785\nEpoch 4/50\n469/469 [==============================] - 2s 5ms/step - loss: 0.0782 - val_loss: 0.0765\nEpoch 5/50\n469/469 [==============================] - 2s 5ms/step - loss: 0.0766 - val_loss: 0.0752\nEpoch 6/50\n469/469 [==============================] - 2s 5ms/step - loss: 0.0754 - val_loss: 0.0743\nEpoch 7/50\n469/469 [==============================] - 2s 5ms/step - loss: 0.0745 - val_loss: 0.0734\nEpoch 8/50\n469/469 [==============================] - 2s 5ms/step - loss: 0.0738 - val_loss: 0.0728\nEpoch 9/50\n469/469 [==============================] - 2s 5ms/step - loss: 0.0733 - val_loss: 0.0723\nEpoch 10/50\n469/469 [==============================] - 2s 5ms/step - loss: 0.0728 - val_loss: 0.0720\nEpoch 11/50\n469/469 [==============================] - 2s 5ms/step - loss: 0.0725 - val_loss: 0.0717\nEpoch 12/50\n469/469 [==============================] - 2s 5ms/step - loss: 0.0722 - val_loss: 0.0716\nEpoch 13/50\n469/469 [==============================] - 2s 5ms/step - loss: 0.0720 - val_loss: 0.0712\nEpoch 14/50\n469/469 [==============================] - 2s 5ms/step - loss: 0.0717 - val_loss: 0.0710\nEpoch 15/50\n469/469 [==============================] - 2s 5ms/step - loss: 0.0716 - val_loss: 0.0708\nEpoch 16/50\n469/469 [==============================] - 2s 5ms/step - loss: 0.0714 - val_loss: 0.0708\nEpoch 17/50\n469/469 [==============================] - 2s 5ms/step - loss: 0.0713 - val_loss: 0.0706\nEpoch 18/50\n469/469 [==============================] - 2s 5ms/step - loss: 0.0711 - val_loss: 0.0705\nEpoch 19/50\n469/469 [==============================] - 2s 5ms/step - loss: 0.0710 - val_loss: 0.0703\nEpoch 20/50\n469/469 [==============================] - 2s 5ms/step - loss: 0.0709 - val_loss: 0.0703\nEpoch 21/50\n469/469 [==============================] - 2s 5ms/step - loss: 0.0708 - val_loss: 0.0701\nEpoch 22/50\n469/469 [==============================] - 2s 5ms/step - loss: 0.0707 - val_loss: 0.0700\nEpoch 23/50\n469/469 [==============================] - 2s 5ms/step - loss: 0.0706 - val_loss: 0.0700\nEpoch 24/50\n469/469 [==============================] - 2s 5ms/step - loss: 0.0705 - val_loss: 0.0698\nEpoch 25/50\n469/469 [==============================] - 2s 5ms/step - loss: 0.0704 - val_loss: 0.0697\nEpoch 26/50\n469/469 [==============================] - 2s 5ms/step - loss: 0.0703 - val_loss: 0.0697\nEpoch 27/50\n469/469 [==============================] - 2s 5ms/step - loss: 0.0702 - val_loss: 0.0696\nEpoch 28/50\n469/469 [==============================] - 2s 5ms/step - loss: 0.0701 - val_loss: 0.0696\nEpoch 29/50\n469/469 [==============================] - 2s 5ms/step - loss: 0.0701 - val_loss: 0.0695\nEpoch 30/50\n469/469 [==============================] - 2s 5ms/step - loss: 0.0700 - val_loss: 0.0694\nEpoch 31/50\n469/469 [==============================] - 2s 5ms/step - loss: 0.0699 - val_loss: 0.0693\nEpoch 32/50\n469/469 [==============================] - 2s 5ms/step - loss: 0.0699 - val_loss: 0.0693\nEpoch 33/50\n469/469 [==============================] - 2s 5ms/step - loss: 0.0698 - val_loss: 0.0693\nEpoch 34/50\n469/469 [==============================] - 2s 5ms/step - loss: 0.0698 - val_loss: 0.0692\nEpoch 35/50\n469/469 [==============================] - 2s 5ms/step - loss: 0.0697 - val_loss: 0.0693\nEpoch 36/50\n469/469 [==============================] - 2s 5ms/step - loss: 0.0697 - val_loss: 0.0691\nEpoch 37/50\n469/469 [==============================] - 2s 5ms/step - loss: 0.0696 - val_loss: 0.0691\nEpoch 38/50\n469/469 [==============================] - 2s 5ms/step - loss: 0.0696 - val_loss: 0.0690\nEpoch 39/50\n469/469 [==============================] - 2s 5ms/step - loss: 0.0695 - val_loss: 0.0690\nEpoch 40/50\n469/469 [==============================] - 2s 5ms/step - loss: 0.0695 - val_loss: 0.0689\nEpoch 41/50\n469/469 [==============================] - 2s 5ms/step - loss: 0.0694 - val_loss: 0.0692\nEpoch 42/50\n469/469 [==============================] - 2s 5ms/step - loss: 0.0694 - val_loss: 0.0688\nEpoch 43/50\n469/469 [==============================] - 2s 5ms/step - loss: 0.0694 - val_loss: 0.0688\nEpoch 44/50\n469/469 [==============================] - 2s 5ms/step - loss: 0.0693 - val_loss: 0.0688\nEpoch 45/50\n469/469 [==============================] - 2s 5ms/step - loss: 0.0693 - val_loss: 0.0687\nEpoch 46/50\n469/469 [==============================] - 2s 5ms/step - loss: 0.0693 - val_loss: 0.0687\nEpoch 47/50\n469/469 [==============================] - 2s 5ms/step - loss: 0.0692 - val_loss: 0.0687\nEpoch 48/50\n469/469 [==============================] - 2s 5ms/step - loss: 0.0692 - val_loss: 0.0686\nEpoch 49/50\n469/469 [==============================] - 2s 5ms/step - loss: 0.0692 - val_loss: 0.0686\nEpoch 50/50\n469/469 [==============================] - 2s 5ms/step - loss: 0.0691 - val_loss: 0.0685\n79/79 [==============================] - 0s 3ms/step - loss: 0.0685\nEvaluation Loss: 0.06852991878986359\n","output_type":"stream"}]},{"cell_type":"code","source":"# Display model summary\nautoencoder.summary()\n","metadata":{"execution":{"iopub.status.busy":"2024-02-27T18:25:57.141284Z","iopub.execute_input":"2024-02-27T18:25:57.141951Z","iopub.status.idle":"2024-02-27T18:25:57.175371Z","shell.execute_reply.started":"2024-02-27T18:25:57.141916Z","shell.execute_reply":"2024-02-27T18:25:57.174603Z"},"trusted":true},"execution_count":39,"outputs":[{"name":"stdout","text":"Model: \"sequential_10\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n conv2d_26 (Conv2D)          (None, 28, 28, 16)        160       \n                                                                 \n max_pooling2d_26 (MaxPooli  (None, 14, 14, 16)        0         \n ng2D)                                                           \n                                                                 \n conv2d_27 (Conv2D)          (None, 14, 14, 8)         1160      \n                                                                 \n max_pooling2d_27 (MaxPooli  (None, 7, 7, 8)           0         \n ng2D)                                                           \n                                                                 \n conv2d_transpose_33 (Conv2  (None, 7, 7, 8)           584       \n DTranspose)                                                     \n                                                                 \n up_sampling2d_26 (UpSampli  (None, 14, 14, 8)         0         \n ng2D)                                                           \n                                                                 \n conv2d_transpose_34 (Conv2  (None, 14, 14, 16)        1168      \n DTranspose)                                                     \n                                                                 \n up_sampling2d_27 (UpSampli  (None, 28, 28, 16)        0         \n ng2D)                                                           \n                                                                 \n conv2d_transpose_35 (Conv2  (None, 28, 28, 1)         145       \n DTranspose)                                                     \n                                                                 \n=================================================================\nTotal params: 3217 (12.57 KB)\nTrainable params: 3217 (12.57 KB)\nNon-trainable params: 0 (0.00 Byte)\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"client_model = models.Sequential(autoencoder.layers[:5])\nserver_model = models.Sequential(autoencoder.layers[5:])","metadata":{"execution":{"iopub.status.busy":"2024-02-27T18:28:44.414825Z","iopub.execute_input":"2024-02-27T18:28:44.415183Z","iopub.status.idle":"2024-02-27T18:28:44.427457Z","shell.execute_reply.started":"2024-02-27T18:28:44.415154Z","shell.execute_reply":"2024-02-27T18:28:44.426632Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"client_model.compile(optimizer='adam', loss='binary_crossentropy')\nserver_model.compile(optimizer='adam', loss='binary_crossentropy')","metadata":{"execution":{"iopub.status.busy":"2024-02-27T18:29:08.400345Z","iopub.execute_input":"2024-02-27T18:29:08.400793Z","iopub.status.idle":"2024-02-27T18:29:08.419330Z","shell.execute_reply.started":"2024-02-27T18:29:08.400765Z","shell.execute_reply":"2024-02-27T18:29:08.418484Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"(x_train, _), (x_test, _) = tf.keras.datasets.mnist.load_data()\nx_train = x_train.astype('float32') / 255.0\nx_test = x_test.astype('float32') / 255.0\nx_train = tf.expand_dims(x_train, axis=-1)\nx_test = tf.expand_dims(x_test, axis=-1)\n\n# Split the dataset into two clients\nx_train_client1, x_train_client2 = x_train[:30000], x_train[30000:]\nx_test_client1, x_test_client2 = x_test[:5000], x_test[5000:]","metadata":{"execution":{"iopub.status.busy":"2024-02-27T18:31:56.876749Z","iopub.execute_input":"2024-02-27T18:31:56.877480Z","iopub.status.idle":"2024-02-27T18:31:57.468407Z","shell.execute_reply.started":"2024-02-27T18:31:56.877438Z","shell.execute_reply":"2024-02-27T18:31:57.467397Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"client1_features = client_model.predict(x_train_client1)","metadata":{"execution":{"iopub.status.busy":"2024-02-27T18:32:57.848270Z","iopub.execute_input":"2024-02-27T18:32:57.849116Z","iopub.status.idle":"2024-02-27T18:33:00.112221Z","shell.execute_reply.started":"2024-02-27T18:32:57.849081Z","shell.execute_reply":"2024-02-27T18:33:00.111175Z"},"trusted":true},"execution_count":45,"outputs":[{"name":"stdout","text":"938/938 [==============================] - 2s 2ms/step\n","output_type":"stream"}]},{"cell_type":"code","source":"client2_features = client_model.predict(x_train_client2)","metadata":{"execution":{"iopub.status.busy":"2024-02-27T18:34:45.550099Z","iopub.execute_input":"2024-02-27T18:34:45.551050Z","iopub.status.idle":"2024-02-27T18:34:47.606765Z","shell.execute_reply.started":"2024-02-27T18:34:45.551014Z","shell.execute_reply":"2024-02-27T18:34:47.605817Z"},"trusted":true},"execution_count":46,"outputs":[{"name":"stdout","text":"938/938 [==============================] - 2s 2ms/step\n","output_type":"stream"}]},{"cell_type":"code","source":"client1_predictions = server_model.predict(client1_features)\nclient2_predictions = server_model.predict(client2_features)","metadata":{"execution":{"iopub.status.busy":"2024-02-27T18:41:10.291539Z","iopub.execute_input":"2024-02-27T18:41:10.292372Z","iopub.status.idle":"2024-02-27T18:41:14.449107Z","shell.execute_reply.started":"2024-02-27T18:41:10.292338Z","shell.execute_reply":"2024-02-27T18:41:14.448312Z"},"trusted":true},"execution_count":49,"outputs":[{"name":"stdout","text":"938/938 [==============================] - 1s 1ms/step\n938/938 [==============================] - 1s 2ms/step\n","output_type":"stream"}]},{"cell_type":"code","source":"evaluation_client1 = server_model.evaluate(client1_features,x_train_client1)","metadata":{"execution":{"iopub.status.busy":"2024-02-27T18:42:47.790343Z","iopub.execute_input":"2024-02-27T18:42:47.790702Z","iopub.status.idle":"2024-02-27T18:42:50.206527Z","shell.execute_reply.started":"2024-02-27T18:42:47.790675Z","shell.execute_reply":"2024-02-27T18:42:50.205687Z"},"trusted":true},"execution_count":50,"outputs":[{"name":"stdout","text":"938/938 [==============================] - 2s 2ms/step - loss: 0.0687\n","output_type":"stream"}]},{"cell_type":"code","source":"evaluation_client2 = server_model.evaluate(client2_features,x_train_client2)","metadata":{"execution":{"iopub.status.busy":"2024-02-27T18:51:37.475249Z","iopub.execute_input":"2024-02-27T18:51:37.476555Z","iopub.status.idle":"2024-02-27T18:51:39.551052Z","shell.execute_reply.started":"2024-02-27T18:51:37.476512Z","shell.execute_reply":"2024-02-27T18:51:39.550044Z"},"trusted":true},"execution_count":51,"outputs":[{"name":"stdout","text":"938/938 [==============================] - 2s 2ms/step - loss: 0.0694\n","output_type":"stream"}]},{"cell_type":"code","source":"test1_features = client_model.predict(x_test_client1)\ntest2_features = client_model.predict(x_test_client2)","metadata":{"execution":{"iopub.status.busy":"2024-02-27T18:56:00.942980Z","iopub.execute_input":"2024-02-27T18:56:00.943360Z","iopub.status.idle":"2024-02-27T18:56:01.674099Z","shell.execute_reply.started":"2024-02-27T18:56:00.943330Z","shell.execute_reply":"2024-02-27T18:56:01.673305Z"},"trusted":true},"execution_count":55,"outputs":[{"name":"stdout","text":"157/157 [==============================] - 0s 2ms/step\n157/157 [==============================] - 0s 2ms/step\n","output_type":"stream"}]},{"cell_type":"code","source":"test_eval = server_model.evaluate(test1_features,x_test_client1)\ntest_eval2 = server_model.evaluate(test2_features,x_test_client2)","metadata":{"execution":{"iopub.status.busy":"2024-02-27T18:57:35.118106Z","iopub.execute_input":"2024-02-27T18:57:35.118780Z","iopub.status.idle":"2024-02-27T18:57:35.883135Z","shell.execute_reply.started":"2024-02-27T18:57:35.118746Z","shell.execute_reply":"2024-02-27T18:57:35.882233Z"},"trusted":true},"execution_count":57,"outputs":[{"name":"stdout","text":"157/157 [==============================] - 0s 2ms/step - loss: 0.0679\n157/157 [==============================] - 0s 2ms/step - loss: 0.0691\n","output_type":"stream"}]}]}